# å›¾åƒé‡‘å­—å¡”ä»£ç å®ç°æŒ‡å— ğŸ”ï¸

æœ¬æ–‡æ¡£æä¾›äº†å›¾åƒé‡‘å­—å¡”ç®—æ³•çš„Pythonå’ŒC++å®Œæ•´å®ç°ä»£ç ã€‚æ¯ä¸ªå®ç°éƒ½åŒ…å«äº†è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜å’Œå‚æ•°è§£é‡Šã€‚

## ç›®å½•
- [1. Pythonå®ç°](#1-pythonå®ç°)
  - [1.1 é«˜æ–¯é‡‘å­—å¡”](#11-é«˜æ–¯é‡‘å­—å¡”)
  - [1.2 æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”](#12-æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”)
  - [1.3 å›¾åƒèåˆ](#13-å›¾åƒèåˆ)
  - [1.4 SIFTå°ºåº¦ç©ºé—´](#14-siftå°ºåº¦ç©ºé—´)
  - [1.5 æ˜¾è‘—æ€§æ£€æµ‹](#15-æ˜¾è‘—æ€§æ£€æµ‹)
- [2. C++å®ç°](#2-cå®ç°)
  - [2.1 é«˜æ–¯é‡‘å­—å¡”](#21-é«˜æ–¯é‡‘å­—å¡”)
  - [2.2 æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”](#22-æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”)
  - [2.3 å›¾åƒèåˆ](#23-å›¾åƒèåˆ)
  - [2.4 SIFTå°ºåº¦ç©ºé—´](#24-siftå°ºåº¦ç©ºé—´)
  - [2.5 æ˜¾è‘—æ€§æ£€æµ‹](#25-æ˜¾è‘—æ€§æ£€æµ‹)

## 1. Pythonå®ç°

### 1.1 é«˜æ–¯é‡‘å­—å¡”

```python
import numpy as np
import cv2

def gaussian_kernel(size: int = 5, sigma: float = 1.0) -> np.ndarray:
    """
    ç”Ÿæˆé«˜æ–¯æ ¸

    å‚æ•°:
        size: int, æ ¸å¤§å°ï¼Œé»˜è®¤5
        sigma: float, æ ‡å‡†å·®ï¼Œé»˜è®¤1.0

    è¿”å›:
        np.ndarray: é«˜æ–¯æ ¸
    """
    kernel = np.zeros((size, size))
    center = size // 2

    for i in range(size):
        for j in range(size):
            x = i - center
            y = j - center
            kernel[i, j] = np.exp(-(x**2 + y**2)/(2*sigma**2))

    return kernel / kernel.sum()

def manual_conv2d(img: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    """
    æ‰‹åŠ¨å®ç°2Då·ç§¯

    å‚æ•°:
        img: np.ndarray, è¾“å…¥å›¾åƒ
        kernel: np.ndarray, å·ç§¯æ ¸

    è¿”å›:
        np.ndarray: å·ç§¯ç»“æœ
    """
    h, w = img.shape
    k_h, k_w = kernel.shape
    pad_h = k_h // 2
    pad_w = k_w // 2

    # å¡«å……å›¾åƒ
    padded = np.pad(img, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')
    output = np.zeros_like(img)

    # æ‰§è¡Œå·ç§¯
    for i in range(h):
        for j in range(w):
            output[i, j] = np.sum(padded[i:i+k_h, j:j+k_w] * kernel)

    return output

def manual_resize(img: np.ndarray, scale_factor: float) -> np.ndarray:
    """
    æ‰‹åŠ¨å®ç°å›¾åƒç¼©æ”¾

    å‚æ•°:
        img: np.ndarray, è¾“å…¥å›¾åƒ
        scale_factor: float, ç¼©æ”¾å› å­

    è¿”å›:
        np.ndarray: ç¼©æ”¾åçš„å›¾åƒ
    """
    if len(img.shape) == 3:
        h, w, c = img.shape
        new_h, new_w = int(h * scale_factor), int(w * scale_factor)
        resized = np.zeros((new_h, new_w, c))

        for k in range(c):
            for i in range(new_h):
                for j in range(new_w):
                    src_i = min(int(i / scale_factor), h-1)
                    src_j = min(int(j / scale_factor), w-1)
                    resized[i, j, k] = img[src_i, src_j, k]
    else:
        h, w = img.shape
        new_h, new_w = int(h * scale_factor), int(w * scale_factor)
        resized = np.zeros((new_h, new_w))

        for i in range(new_h):
            for j in range(new_w):
                src_i = min(int(i / scale_factor), h-1)
                src_j = min(int(j / scale_factor), w-1)
                resized[i, j] = img[src_i, src_j]

    return resized

def gaussian_pyramid(img_path: str, levels: int = 4) -> np.ndarray:
    """
    æ„å»ºå›¾åƒçš„é«˜æ–¯é‡‘å­—å¡”

    å‚æ•°:
        img_path: str, è¾“å…¥å›¾åƒè·¯å¾„
        levels: int, é‡‘å­—å¡”å±‚æ•°ï¼Œé»˜è®¤4

    è¿”å›:
        np.ndarray: é«˜æ–¯é‡‘å­—å¡”å¯è§†åŒ–ç»“æœ
    """
    # è¯»å–å›¾åƒ
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

    # è½¬æ¢ä¸ºç°åº¦å›¾
    if len(img.shape) == 3:
        gray = np.mean(img, axis=2).astype(np.uint8)
    else:
        gray = img

    # åˆ›å»ºé«˜æ–¯æ ¸
    kernel = gaussian_kernel()

    # æ„å»ºé‡‘å­—å¡”
    pyramid = [gray]
    current = gray.copy()

    for _ in range(levels-1):
        # é«˜æ–¯æ»¤æ³¢
        filtered = manual_conv2d(current, kernel)
        # ä¸‹é‡‡æ ·
        downsampled = manual_resize(filtered, 0.5)
        pyramid.append(downsampled)
        current = downsampled

    # å¯è§†åŒ–ç»“æœ
    result = []
    for level in pyramid:
        # å°†å›¾åƒè°ƒæ•´ä¸ºç›¸åŒå¤§å°ä»¥ä¾¿æ˜¾ç¤º
        resized = manual_resize(level, (pyramid[0].shape[1]/level.shape[1]))
        if len(resized.shape) == 2:
            resized = cv2.cvtColor(resized.astype(np.uint8), cv2.COLOR_GRAY2BGR)
        result.append(resized)

    return np.hstack(result)
```

### 1.2 æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”

```python
def laplacian_pyramid(img_path: str, levels: int = 4) -> np.ndarray:
    """
    æ„å»ºå›¾åƒçš„æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”

    å‚æ•°:
        img_path: str, è¾“å…¥å›¾åƒè·¯å¾„
        levels: int, é‡‘å­—å¡”å±‚æ•°ï¼Œé»˜è®¤4

    è¿”å›:
        np.ndarray: æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”å¯è§†åŒ–ç»“æœ
    """
    # è¯»å–å›¾åƒ
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

    # è½¬æ¢ä¸ºç°åº¦å›¾
    if len(img.shape) == 3:
        gray = np.mean(img, axis=2).astype(np.uint8)
    else:
        gray = img

    # åˆ›å»ºé«˜æ–¯æ ¸
    kernel = gaussian_kernel()

    # æ„å»ºé«˜æ–¯é‡‘å­—å¡”
    gaussian_pyr = [gray]
    current = gray.copy()

    for _ in range(levels-1):
        filtered = manual_conv2d(current, kernel)
        downsampled = manual_resize(filtered, 0.5)
        gaussian_pyr.append(downsampled)
        current = downsampled

    # æ„å»ºæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
    laplacian_pyr = []
    for i in range(levels-1):
        # ä¸Šé‡‡æ ·
        upsampled = manual_resize(gaussian_pyr[i+1], 2.0)
        # è°ƒæ•´å¤§å°ä»¥åŒ¹é…
        if upsampled.shape[0] > gaussian_pyr[i].shape[0]:
            upsampled = upsampled[:gaussian_pyr[i].shape[0], :]
        if upsampled.shape[1] > gaussian_pyr[i].shape[1]:
            upsampled = upsampled[:, :gaussian_pyr[i].shape[1]]
        # è®¡ç®—å·®åˆ†
        diff = gaussian_pyr[i] - upsampled
        laplacian_pyr.append(diff)

    # æ·»åŠ æœ€åä¸€å±‚
    laplacian_pyr.append(gaussian_pyr[-1])

    # å¯è§†åŒ–ç»“æœ
    result = []
    for level in laplacian_pyr:
        # å°†å›¾åƒè°ƒæ•´ä¸ºç›¸åŒå¤§å°ä»¥ä¾¿æ˜¾ç¤º
        resized = manual_resize(level, (laplacian_pyr[0].shape[1]/level.shape[1]))
        if len(resized.shape) == 2:
            resized = cv2.cvtColor(resized.astype(np.uint8), cv2.COLOR_GRAY2BGR)
        result.append(resized)

    return np.hstack(result)
```

### 1.3 å›¾åƒèåˆ

```python
def image_blending(img_path1: str, img_path2: str, levels: int = 4) -> np.ndarray:
    """
    ä½¿ç”¨é‡‘å­—å¡”è¿›è¡Œå›¾åƒèåˆ

    å‚æ•°:
        img_path1: str, ç¬¬ä¸€å¼ è¾“å…¥å›¾åƒè·¯å¾„
        img_path2: str, ç¬¬äºŒå¼ è¾“å…¥å›¾åƒè·¯å¾„
        levels: int, é‡‘å­—å¡”å±‚æ•°ï¼Œé»˜è®¤4

    è¿”å›:
        np.ndarray: èåˆç»“æœ
    """
    # è¯»å–å›¾åƒ
    img1 = cv2.imread(img_path1)
    img2 = cv2.imread(img_path2)
    if img1 is None or img2 is None:
        raise ValueError("æ— æ³•è¯»å–å›¾åƒ")

    # ç¡®ä¿ä¸¤å¼ å›¾åƒå¤§å°ç›¸åŒ
    if img1.shape != img2.shape:
        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))

    def build_laplacian_pyramid(img):
        # æ„å»ºé«˜æ–¯é‡‘å­—å¡”
        gaussian_pyr = [img]
        current = img.copy()
        for _ in range(levels-1):
            current = cv2.pyrDown(current)
            gaussian_pyr.append(current)

        # æ„å»ºæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
        laplacian_pyr = []
        for i in range(levels-1):
            size = (gaussian_pyr[i].shape[1], gaussian_pyr[i].shape[0])
            upsampled = cv2.pyrUp(gaussian_pyr[i+1], dstsize=size)
            laplacian = cv2.subtract(gaussian_pyr[i], upsampled)
            laplacian_pyr.append(laplacian)
        laplacian_pyr.append(gaussian_pyr[-1])
        return laplacian_pyr

    # æ„å»ºä¸¤ä¸ªå›¾åƒçš„æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
    lap_pyr1 = build_laplacian_pyramid(img1)
    lap_pyr2 = build_laplacian_pyramid(img2)

    # èåˆé‡‘å­—å¡”
    blended_pyr = []
    for lap1, lap2 in zip(lap_pyr1, lap_pyr2):
        # åœ¨ä¸­é—´ä½ç½®èåˆ
        rows, cols = lap1.shape[:2]
        mask = np.zeros((rows, cols, 3))
        mask[:, :cols//2] = 1
        blended = lap1 * mask + lap2 * (1 - mask)
        blended_pyr.append(blended)

    # é‡å»ºèåˆå›¾åƒ
    result = blended_pyr[-1]
    for i in range(levels-2, -1, -1):
        size = (blended_pyr[i].shape[1], blended_pyr[i].shape[0])
        result = cv2.pyrUp(result, dstsize=size)
        result = cv2.add(result, blended_pyr[i])

    return result
```

### 1.4 SIFTå°ºåº¦ç©ºé—´

```python
def sift_scale_space(img_path: str, octaves: int = 4, scales: int = 5, sigma: float = 1.6) -> np.ndarray:
    """
    æ„å»ºSIFTç®—æ³•çš„å°ºåº¦ç©ºé—´

    å‚æ•°:
        img_path: str, è¾“å…¥å›¾åƒè·¯å¾„
        octaves: int, ç»„æ•°ï¼Œé»˜è®¤4
        scales: int, æ¯ç»„çš„å°ºåº¦æ•°ï¼Œé»˜è®¤5
        sigma: float, åˆå§‹sigmaå€¼ï¼Œé»˜è®¤1.6

    è¿”å›:
        np.ndarray: å°ºåº¦ç©ºé—´å¯è§†åŒ–ç»“æœ
    """
    # è¯»å–å›¾åƒ
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

    # å›¾åƒä¸Šé‡‡æ ·
    img = cv2.resize(img, None, fx=2, fy=2)

    # åˆå§‹åŒ–å°ºåº¦ç©ºé—´
    scale_space = []
    k = 2 ** (1/scales)  # å°ºåº¦å› å­

    # æ„å»ºå°ºåº¦ç©ºé—´
    for o in range(octaves):
        octave = []
        if o == 0:
            base = cv2.GaussianBlur(img, (0, 0), sigma)
        else:
            base = cv2.resize(scale_space[-1][-3], None, fx=0.5, fy=0.5)

        current_sigma = sigma
        octave.append(base)

        # ç”Ÿæˆæ¯ä¸ªå°ºåº¦çš„å›¾åƒ
        for s in range(scales-1):
            current_sigma *= k
            blurred = cv2.GaussianBlur(base, (0, 0), current_sigma)
            octave.append(blurred)

        scale_space.append(octave)
        base = octave[-3]  # ä¸ºä¸‹ä¸€ç»„å‡†å¤‡åŸºç¡€å›¾åƒ

    # å¯è§†åŒ–ç»“æœ
    result = []
    for octave in scale_space:
        # è°ƒæ•´æ¯ä¸ªå°ºåº¦çš„å¤§å°ä»¥ä¾¿æ˜¾ç¤º
        resized_octave = []
        for img in octave:
            size = (scale_space[0][0].shape[1], scale_space[0][0].shape[0])
            resized = cv2.resize(img, size)
            resized_octave.append(resized)
        result.append(np.hstack(resized_octave))

    return np.vstack(result)
```

### 1.5 æ˜¾è‘—æ€§æ£€æµ‹

```python
def saliency_detection(img_path: str, levels: int = 4) -> np.ndarray:
    """
    åŸºäºé‡‘å­—å¡”çš„æ˜¾è‘—æ€§æ£€æµ‹

    å‚æ•°:
        img_path: str, è¾“å…¥å›¾åƒè·¯å¾„
        levels: int, é‡‘å­—å¡”å±‚æ•°ï¼Œé»˜è®¤4

    è¿”å›:
        np.ndarray: æ˜¾è‘—æ€§æ£€æµ‹ç»“æœ
    """
    # è¯»å–å›¾åƒ
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

    # è½¬æ¢åˆ°Labé¢œè‰²ç©ºé—´
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)

    # æ„å»ºé«˜æ–¯é‡‘å­—å¡”
    pyramids = []
    for i in range(3):  # å¯¹æ¯ä¸ªé€šé“
        channel = lab[:, :, i]
        pyramid = [channel]
        for _ in range(levels-1):
            channel = cv2.pyrDown(channel)
            pyramid.append(channel)
        pyramids.append(pyramid)

    # è®¡ç®—æ˜¾è‘—æ€§å›¾
    saliency = np.zeros_like(img[:, :, 0], dtype=np.float32)
    for i in range(3):  # å¯¹æ¯ä¸ªé€šé“
        channel_saliency = np.zeros_like(saliency)
        for level in range(levels):
            # è°ƒæ•´å½“å‰å±‚çš„å¤§å°
            size = (img.shape[1], img.shape[0])
            resized = cv2.resize(pyramids[i][level], size)
            # è®¡ç®—ä¸å¹³å‡å€¼çš„å·®å¼‚
            mean = np.mean(resized)
            channel_saliency += np.abs(resized - mean)
        saliency += channel_saliency

    # å½’ä¸€åŒ–
    saliency = cv2.normalize(saliency, None, 0, 255, cv2.NORM_MINMAX)
    saliency = saliency.astype(np.uint8)

    # åº”ç”¨é¢œè‰²æ˜ å°„ä»¥ä¾¿å¯è§†åŒ–
    saliency_color = cv2.applyColorMap(saliency, cv2.COLORMAP_JET)

    # å°†åŸå›¾å’Œæ˜¾è‘—æ€§å›¾å¹¶æ’æ˜¾ç¤º
    result = np.hstack([img, saliency_color])

    return result
```

## 2. C++å®ç°

### 2.1 é«˜æ–¯é‡‘å­—å¡”

```cpp
#include <opencv2/opencv.hpp>
#include <vector>

cv::Mat gaussianPyramid(const std::string& imgPath, int levels = 4) {
    // è¯»å–å›¾åƒ
    cv::Mat img = cv::imread(imgPath);
    if (img.empty()) {
        throw std::runtime_error("æ— æ³•è¯»å–å›¾åƒ");
    }

    // è½¬æ¢ä¸ºç°åº¦å›¾
    cv::Mat gray;
    cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);

    // æ„å»ºé‡‘å­—å¡”
    std::vector<cv::Mat> pyramid;
    pyramid.push_back(gray);
    cv::Mat current = gray.clone();

    for (int i = 0; i < levels-1; i++) {
        cv::Mat down;
        cv::pyrDown(current, down);
        pyramid.push_back(down);
        current = down;
    }

    // å¯è§†åŒ–ç»“æœ
    std::vector<cv::Mat> resized;
    for (const auto& level : pyramid) {
        cv::Mat temp;
        cv::resize(level, temp, pyramid[0].size());
        cv::Mat colored;
        cv::cvtColor(temp, colored, cv::COLOR_GRAY2BGR);
        resized.push_back(colored);
    }

    // æ°´å¹³æ‹¼æ¥æ‰€æœ‰å±‚
    cv::Mat result;
    cv::hconcat(resized, result);

    return result;
}
```

### 2.2 æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”

```cpp
cv::Mat laplacianPyramid(const std::string& imgPath, int levels = 4) {
    // è¯»å–å›¾åƒ
    cv::Mat img = cv::imread(imgPath);
    if (img.empty()) {
        throw std::runtime_error("æ— æ³•è¯»å–å›¾åƒ");
    }

    // è½¬æ¢ä¸ºç°åº¦å›¾
    cv::Mat gray;
    cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);

    // æ„å»ºé«˜æ–¯é‡‘å­—å¡”
    std::vector<cv::Mat> gaussianPyr;
    gaussianPyr.push_back(gray);
    cv::Mat current = gray.clone();

    for (int i = 0; i < levels-1; i++) {
        cv::Mat down;
        cv::pyrDown(current, down);
        gaussianPyr.push_back(down);
        current = down;
    }

    // æ„å»ºæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
    std::vector<cv::Mat> laplacianPyr;
    for (int i = 0; i < levels-1; i++) {
        cv::Mat up;
        cv::pyrUp(gaussianPyr[i+1], up, gaussianPyr[i].size());
        cv::Mat diff = gaussianPyr[i] - up;
        laplacianPyr.push_back(diff);
    }
    laplacianPyr.push_back(gaussianPyr.back());

    // å¯è§†åŒ–ç»“æœ
    std::vector<cv::Mat> resized;
    for (const auto& level : laplacianPyr) {
        cv::Mat temp;
        cv::resize(level, temp, laplacianPyr[0].size());
        cv::Mat colored;
        cv::cvtColor(temp, colored, cv::COLOR_GRAY2BGR);
        resized.push_back(colored);
    }

    // æ°´å¹³æ‹¼æ¥æ‰€æœ‰å±‚
    cv::Mat result;
    cv::hconcat(resized, result);

    return result;
}
```

### 2.3 å›¾åƒèåˆ

```cpp
cv::Mat imageBlending(const std::string& imgPath1, const std::string& imgPath2, int levels = 4) {
    // è¯»å–å›¾åƒ
    cv::Mat img1 = cv::imread(imgPath1);
    cv::Mat img2 = cv::imread(imgPath2);
    if (img1.empty() || img2.empty()) {
        throw std::runtime_error("æ— æ³•è¯»å–å›¾åƒ");
    }

    // ç¡®ä¿ä¸¤å¼ å›¾åƒå¤§å°ç›¸åŒ
    if (img1.size() != img2.size()) {
        cv::resize(img2, img2, img1.size());
    }

    // æ„å»ºæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”çš„lambdaå‡½æ•°
    auto buildLaplacianPyramid = [](const cv::Mat& img, int levels) {
        std::vector<cv::Mat> gaussianPyr;
        std::vector<cv::Mat> laplacianPyr;

        // æ„å»ºé«˜æ–¯é‡‘å­—å¡”
        gaussianPyr.push_back(img);
        cv::Mat current = img.clone();
        for (int i = 0; i < levels-1; i++) {
            cv::Mat down;
            cv::pyrDown(current, down);
            gaussianPyr.push_back(down);
            current = down;
        }

        // æ„å»ºæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
        for (int i = 0; i < levels-1; i++) {
            cv::Mat up;
            cv::pyrUp(gaussianPyr[i+1], up, gaussianPyr[i].size());
            cv::Mat diff = gaussianPyr[i] - up;
            laplacianPyr.push_back(diff);
        }
        laplacianPyr.push_back(gaussianPyr.back());

        return laplacianPyr;
    };

    // æ„å»ºä¸¤ä¸ªå›¾åƒçš„æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”
    auto lapPyr1 = buildLaplacianPyramid(img1, levels);
    auto lapPyr2 = buildLaplacianPyramid(img2, levels);

    // èåˆé‡‘å­—å¡”
    std::vector<cv::Mat> blendedPyr;
    for (int i = 0; i < levels; i++) {
        cv::Mat mask = cv::Mat::zeros(lapPyr1[i].size(), CV_8UC3);
        mask(cv::Rect(0, 0, lapPyr1[i].cols/2, lapPyr1[i].rows)).setTo(cv::Scalar(1,1,1));

        cv::Mat blended;
        cv::multiply(lapPyr1[i], mask, blended);
        cv::multiply(lapPyr2[i], cv::Scalar(1,1,1) - mask, mask);
        blended += mask;

        blendedPyr.push_back(blended);
    }

    // é‡å»ºèåˆå›¾åƒ
    cv::Mat result = blendedPyr.back();
    for (int i = levels-2; i >= 0; i--) {
        cv::Mat up;
        cv::pyrUp(result, up, blendedPyr[i].size());
        result = up + blendedPyr[i];
    }

    return result;
}
```

### 2.4 SIFTå°ºåº¦ç©ºé—´

```cpp
cv::Mat siftScaleSpace(const std::string& imgPath, int octaves = 4, int scales = 5, double sigma = 1.6) {
    // è¯»å–å›¾åƒ
    cv::Mat img = cv::imread(imgPath, cv::IMREAD_GRAYSCALE);
    if (img.empty()) {
        throw std::runtime_error("æ— æ³•è¯»å–å›¾åƒ");
    }

    // å›¾åƒä¸Šé‡‡æ ·
    cv::Mat upsampled;
    cv::resize(img, upsampled, cv::Size(), 2, 2);

    // åˆå§‹åŒ–å°ºåº¦ç©ºé—´
    std::vector<std::vector<cv::Mat>> scaleSpace;
    double k = std::pow(2.0, 1.0/scales);  // å°ºåº¦å› å­

    // æ„å»ºå°ºåº¦ç©ºé—´
    for (int o = 0; o < octaves; o++) {
        std::vector<cv::Mat> octave;
        cv::Mat base;

        if (o == 0) {
            cv::GaussianBlur(upsampled, base, cv::Size(), sigma);
        } else {
            cv::resize(scaleSpace.back()[scales-3], base, cv::Size(), 0.5, 0.5);
        }

        double currentSigma = sigma;
        octave.push_back(base);

        // ç”Ÿæˆæ¯ä¸ªå°ºåº¦çš„å›¾åƒ
        for (int s = 1; s < scales; s++) {
            currentSigma *= k;
            cv::Mat blurred;
            cv::GaussianBlur(base, blurred, cv::Size(), currentSigma);
            octave.push_back(blurred);
        }

        scaleSpace.push_back(octave);
        base = octave[scales-3];
    }

    // å¯è§†åŒ–ç»“æœ
    std::vector<cv::Mat> rows;
    for (const auto& octave : scaleSpace) {
        std::vector<cv::Mat> resizedOctave;
        for (const auto& img : octave) {
            cv::Mat resized;
            cv::resize(img, resized, scaleSpace[0][0].size());
            cv::Mat colored;
            cv::cvtColor(resized, colored, cv::COLOR_GRAY2BGR);
            resizedOctave.push_back(colored);
        }
        cv::Mat row;
        cv::hconcat(resizedOctave, row);
        rows.push_back(row);
    }

    cv::Mat result;
    cv::vconcat(rows, result);

    return result;
}
```

### 2.5 æ˜¾è‘—æ€§æ£€æµ‹

```cpp
cv::Mat saliencyDetection(const std::string& imgPath, int levels = 4) {
    // è¯»å–å›¾åƒ
    cv::Mat img = cv::imread(imgPath);
    if (img.empty()) {
        throw std::runtime_error("æ— æ³•è¯»å–å›¾åƒ");
    }

    // è½¬æ¢åˆ°Labé¢œè‰²ç©ºé—´
    cv::Mat lab;
    cv::cvtColor(img, lab, cv::COLOR_BGR2Lab);

    // åˆ†ç¦»é€šé“
    std::vector<cv::Mat> channels;
    cv::split(lab, channels);

    // æ„å»ºé«˜æ–¯é‡‘å­—å¡”
    std::vector<std::vector<cv::Mat>> pyramids(3);
    for (int i = 0; i < 3; i++) {
        pyramids[i].push_back(channels[i]);
        cv::Mat current = channels[i];
        for (int j = 0; j < levels-1; j++) {
            cv::Mat down;
            cv::pyrDown(current, down);
            pyramids[i].push_back(down);
            current = down;
        }
    }

    // è®¡ç®—æ˜¾è‘—æ€§å›¾
    cv::Mat saliency = cv::Mat::zeros(img.size(), CV_32F);
    for (int i = 0; i < 3; i++) {
        cv::Mat channelSaliency = cv::Mat::zeros(img.size(), CV_32F);
        for (int level = 0; level < levels; level++) {
            cv::Mat resized;
            cv::resize(pyramids[i][level], resized, img.size());
            cv::Scalar mean = cv::mean(resized);
            cv::Mat diff;
            cv::absdiff(resized, mean, diff);
            channelSaliency += diff;
        }
        saliency += channelSaliency;
    }

    // å½’ä¸€åŒ–
    cv::normalize(saliency, saliency, 0, 255, cv::NORM_MINMAX);
    saliency.convertTo(saliency, CV_8U);

    // åº”ç”¨é¢œè‰²æ˜ å°„ä»¥ä¾¿å¯è§†åŒ–
    cv::Mat saliencyColor;
    cv::applyColorMap(saliency, saliencyColor, cv::COLORMAP_JET);

    // å°†åŸå›¾å’Œæ˜¾è‘—æ€§å›¾å¹¶æ’æ˜¾ç¤º
    cv::Mat result;
    cv::hconcat(std::vector<cv::Mat>{img, saliencyColor}, result);

    return result;
}
```