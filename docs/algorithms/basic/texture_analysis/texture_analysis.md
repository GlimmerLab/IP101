# çº¹ç†åˆ†æè¯¦è§£ ğŸ¨

> çº¹ç†åˆ†æå°±åƒæ˜¯ç»™å›¾åƒåš"æŒ‡çº¹è¯†åˆ«"ï¼æ¯ç§çº¹ç†éƒ½æœ‰å…¶ç‹¬ç‰¹çš„"æŒ‡çº¹"ï¼Œå°±åƒæœ¨çº¹çš„æ¡çº¹ã€å¸ƒæ–™çš„ç¼–ç»‡ã€è‰åœ°çš„éšæœºåˆ†å¸ƒä¸€æ ·ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ¥æ¢ç´¢è¿™ä¸ªæ—¢æœ‰è¶£åˆå®ç”¨çš„å›¾åƒå¤„ç†é¢†åŸŸå§ï¼

## ç›®å½•
- [1. ä»€ä¹ˆæ˜¯çº¹ç†åˆ†æï¼Ÿ](#1-ä»€ä¹ˆæ˜¯çº¹ç†åˆ†æ)
- [2. ç°åº¦å…±ç”ŸçŸ©é˜µ(GLCM)](#2-ç°åº¦å…±ç”ŸçŸ©é˜µglcm)
- [3. ç»Ÿè®¡ç‰¹å¾åˆ†æ](#3-ç»Ÿè®¡ç‰¹å¾åˆ†æ)
- [4. å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)](#4-å±€éƒ¨äºŒå€¼æ¨¡å¼lbp)
- [5. Gaborçº¹ç†ç‰¹å¾](#5-gaborçº¹ç†ç‰¹å¾)
- [6. çº¹ç†åˆ†ç±»](#6-çº¹ç†åˆ†ç±»)
- [7. ä»£ç å®ç°ä¸ä¼˜åŒ–](#7-ä»£ç å®ç°ä¸ä¼˜åŒ–)
- [8. å®éªŒç»“æœä¸åˆ†æ](#8-å®éªŒç»“æœä¸åˆ†æ)

## 1. ä»€ä¹ˆæ˜¯çº¹ç†åˆ†æï¼Ÿ

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ­£åœ¨çœ‹ä¸€å¼ æœ¨æ¡Œçš„ç…§ç‰‡ã€‚å³ä½¿ä¸çœ‹æ•´ä½“å½¢çŠ¶ï¼Œä½ ä¹Ÿèƒ½é€šè¿‡æœ¨çº¹çš„æ¡çº¹è®¤å‡ºè¿™æ˜¯æœ¨å¤´ã€‚è¿™å°±æ˜¯çº¹ç†åˆ†æçš„é­…åŠ›æ‰€åœ¨ï¼å®ƒå°±åƒæ˜¯åœ¨ç ”ç©¶å›¾åƒçš„"è‚Œç†"ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£å›¾åƒçš„ç»†èŠ‚ç‰¹å¾ã€‚

å¸¸è§çš„çº¹ç†ç±»å‹ï¼š
- ğŸŒ³ æœ¨çº¹ï¼šæ¡çŠ¶æ’åˆ—ï¼Œå°±åƒæ ‘æœ¨çš„å¹´è½®
- ğŸ‘• å¸ƒæ–™ï¼šè§„åˆ™çš„ç¼–ç»‡æ–¹å¼ï¼Œå°±åƒç»‡æ¯›è¡£çš„é’ˆæ³•
- ğŸŒ± è‰åœ°ï¼šéšæœºåˆ†å¸ƒï¼Œå°±åƒæ’’åœ¨åœ°ä¸Šçš„èŠéº»
- ğŸ§± ç –å¢™ï¼šè§„åˆ™æ’åˆ—ï¼Œå°±åƒä¹é«˜ç§¯æœ¨

é€šè¿‡åˆ†æè¿™äº›"æŒ‡çº¹"ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š
- ğŸ” è¯†åˆ«ä¸åŒæè´¨ï¼ˆæ˜¯æœ¨å¤´è¿˜æ˜¯çŸ³å¤´ï¼Ÿï¼‰
- âœ‚ï¸ è¿›è¡Œå›¾åƒåˆ†å‰²ï¼ˆæŠŠæœ¨å¤´å’ŒçŸ³å¤´åˆ†å¼€ï¼‰
- ğŸ¯ å®ç°ç›®æ ‡æ£€æµ‹ï¼ˆæ‰¾åˆ°æ‰€æœ‰çš„æœ¨å¤´ï¼‰
- ğŸ“Š è¯„ä¼°è¡¨é¢è´¨é‡ï¼ˆè¿™å—æœ¨å¤´è´¨é‡å¦‚ä½•ï¼Ÿï¼‰

## 2. ç°åº¦å…±ç”ŸçŸ©é˜µ(GLCM)

### 2.1 åŸºæœ¬åŸç†

GLCMå°±åƒæ˜¯ç»™å›¾åƒåš"åƒç´ é…å¯¹"ï¼å®ƒç»Ÿè®¡äº†å›¾åƒä¸­åƒç´ å¯¹çš„ç°åº¦å…³ç³»ï¼Œå°±åƒæ˜¯åœ¨ç©"æ‰¾æœ‹å‹"æ¸¸æˆã€‚

ä¸¾ä¸ªä¾‹å­ï¼š
- å¦‚æœä¸¤ä¸ªåƒç´ çš„ç°åº¦å€¼éƒ½æ˜¯100ï¼Œå®ƒä»¬å°±æ˜¯"å¥½æœ‹å‹"
- å¦‚æœä¸€ä¸ªæ˜¯100ï¼Œå¦ä¸€ä¸ªæ˜¯200ï¼Œå®ƒä»¬å°±æ˜¯"æ™®é€šæœ‹å‹"
- GLCMå°±æ˜¯ç»Ÿè®¡è¿™äº›"æœ‹å‹å…³ç³»"çš„é¢‘ç‡

æ•°å­¦è¡¨è¾¾å¼ï¼š
$$
P(i,j) = \frac{\text{åƒç´ å¯¹(i,j)çš„æ•°é‡}}{\text{æ€»çš„åƒç´ å¯¹æ•°é‡}}
$$

### 2.2 Haralickç‰¹å¾

åŸºäºGLCMï¼Œæˆ‘ä»¬å¯ä»¥æå–å¤šç§æœ‰è¶£çš„çº¹ç†ç‰¹å¾ï¼Œå°±åƒæ˜¯åœ¨ç»™çº¹ç†åš"ä½“æ£€"ï¼š

1. å¯¹æ¯”åº¦(Contrast)ï¼šè¡¡é‡åƒç´ å¯¹çš„å·®å¼‚ç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"æœ‹å‹ä¹‹é—´çš„èº«é«˜å·®"
   - å·®å¼‚è¶Šå¤§ï¼Œå¯¹æ¯”åº¦è¶Šé«˜
   $$
   \text{Contrast} = \sum_{i,j} |i-j|^2 P(i,j)
   $$

2. ç›¸å…³æ€§(Correlation)ï¼šè¡¡é‡åƒç´ å¯¹çš„çº¿æ€§å…³ç³»
   - å°±åƒæ˜¯åœ¨çœ‹"æœ‹å‹ä¹‹é—´çš„ç›¸ä¼¼åº¦"
   - ç›¸å…³æ€§è¶Šé«˜ï¼Œè¯´æ˜çº¹ç†è¶Šè§„åˆ™
   $$
   \text{Correlation} = \sum_{i,j} \frac{(i-\mu_i)(j-\mu_j)P(i,j)}{\sigma_i \sigma_j}
   $$

3. èƒ½é‡(Energy)ï¼šè¡¡é‡çº¹ç†çš„å‡åŒ€ç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"æœ‹å‹å…³ç³»çš„ç¨³å®šæ€§"
   - èƒ½é‡è¶Šé«˜ï¼Œè¯´æ˜çº¹ç†è¶Šå‡åŒ€
   $$
   \text{Energy} = \sum_{i,j} P(i,j)^2
   $$

4. åŒè´¨æ€§(Homogeneity)ï¼šè¡¡é‡çº¹ç†çš„å¹³æ»‘ç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"æœ‹å‹ä¹‹é—´çš„å’Œè°åº¦"
   - åŒè´¨æ€§è¶Šé«˜ï¼Œè¯´æ˜çº¹ç†è¶Šå¹³æ»‘
   $$
   \text{Homogeneity} = \sum_{i,j} \frac{P(i,j)}{1+(i-j)^2}
   $$

### 2.3 ä»£ç å®ç°

#### C++å®ç°
```cpp
Mat compute_glcm(const Mat& src, int distance, int angle) {
    Mat glcm = Mat::zeros(GRAY_LEVELS, GRAY_LEVELS, CV_32F);

    // Calculate offsets
    int dx = 0, dy = 0;
    switch(angle) {
        case 0:   dx = distance; dy = 0;  break;
        case 45:  dx = distance; dy = -distance; break;
        case 90:  dx = 0; dy = -distance; break;
        case 135: dx = -distance; dy = -distance; break;
        default:  dx = distance; dy = 0;  break;
    }

    // Calculate GLCM
    #pragma omp parallel for
    for(int i = 0; i < src.rows; i++) {
        for(int j = 0; j < src.cols; j++) {
            int ni = i + dy;
            int nj = j + dx;
            if(ni >= 0 && ni < src.rows && nj >= 0 && nj < src.cols) {
                int val1 = src.at<uchar>(i,j);
                int val2 = src.at<uchar>(ni,nj);
                #pragma omp atomic
                glcm.at<float>(val1,val2)++;
            }
        }
    }

    // Normalize
    glcm /= sum(glcm)[0];

    return glcm;
}

vector<double> extract_haralick_features(const Mat& glcm) {
    vector<double> features;
    features.reserve(4);  // 4 Haralick features

    double contrast = 0, correlation = 0, energy = 0, homogeneity = 0;
    double mean_i = 0, mean_j = 0, std_i = 0, std_j = 0;

    // Calculate mean and standard deviation
    for(int i = 0; i < GRAY_LEVELS; i++) {
        for(int j = 0; j < GRAY_LEVELS; j++) {
            double p_ij = static_cast<double>(glcm.at<float>(i,j));
            mean_i += i * p_ij;
            mean_j += j * p_ij;
        }
    }

    for(int i = 0; i < GRAY_LEVELS; i++) {
        for(int j = 0; j < GRAY_LEVELS; j++) {
            double p_ij = static_cast<double>(glcm.at<float>(i,j));
            std_i += (i - mean_i) * (i - mean_i) * p_ij;
            std_j += (j - mean_j) * (j - mean_j) * p_ij;
        }
    }
    std_i = sqrt(std_i);
    std_j = sqrt(std_j);

    // Calculate Haralick features
    #pragma omp parallel sections
    {
        #pragma omp section
        {
            for(int i = 0; i < GRAY_LEVELS; i++) {
                for(int j = 0; j < GRAY_LEVELS; j++) {
                    double p_ij = static_cast<double>(glcm.at<float>(i,j));
                    contrast += (i-j)*(i-j) * p_ij;
                }
            }
        }

        #pragma omp section
        {
            for(int i = 0; i < GRAY_LEVELS; i++) {
                for(int j = 0; j < GRAY_LEVELS; j++) {
                    double p_ij = static_cast<double>(glcm.at<float>(i,j));
                    correlation += ((i-mean_i)*(j-mean_j)*p_ij)/(std_i*std_j);
                }
            }
        }

        #pragma omp section
        {
            for(int i = 0; i < GRAY_LEVELS; i++) {
                for(int j = 0; j < GRAY_LEVELS; j++) {
                    double p_ij = static_cast<double>(glcm.at<float>(i,j));
                    energy += p_ij * p_ij;
                }
            }
        }

        #pragma omp section
        {
            for(int i = 0; i < GRAY_LEVELS; i++) {
                for(int j = 0; j < GRAY_LEVELS; j++) {
                    double p_ij = static_cast<double>(glcm.at<float>(i,j));
                    homogeneity += p_ij/(1+(i-j)*(i-j));
                }
            }
        }
    }

    features.push_back(contrast);
    features.push_back(correlation);
    features.push_back(energy);
    features.push_back(homogeneity);

    return features;
}
```

#### Pythonå®ç°
```python
def compute_glcm(img: np.ndarray, d: int = 1, theta: int = 0) -> np.ndarray:
    """è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ(GLCM)

    Args:
        img: è¾“å…¥å›¾åƒ
        d: è·ç¦»
        theta: è§’åº¦(0,45,90,135åº¦)

    Returns:
        np.ndarray: GLCMçŸ©é˜µ
    """
    # ç¡®ä¿å›¾åƒæ˜¯ç°åº¦å›¾
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # é‡åŒ–ç°åº¦çº§
    levels = 8
    img = (img // (256 // levels)).astype(np.uint8)

    # åˆ›å»ºGLCMçŸ©é˜µ
    glcm = np.zeros((levels, levels), dtype=np.uint32)

    # æ ¹æ®è§’åº¦ç¡®å®šåç§»
    if theta == 0:
        dx, dy = d, 0
    elif theta == 45:
        dx, dy = d, -d
    elif theta == 90:
        dx, dy = 0, d
    else:  # 135åº¦
        dx, dy = -d, d

    # è®¡ç®—GLCM
    h, w = img.shape
    for i in range(h):
        for j in range(w):
            if 0 <= i+dy < h and 0 <= j+dx < w:
                glcm[img[i,j], img[i+dy,j+dx]] += 1

    # å½’ä¸€åŒ–
    glcm = glcm.astype(np.float32)
    if np.sum(glcm) > 0:
        glcm /= np.sum(glcm)

    return glcm

def extract_haralick_features(glcm: np.ndarray) -> List[float]:
    """æå–Haralickç‰¹å¾

    Args:
        glcm: ç°åº¦å…±ç”ŸçŸ©é˜µ

    Returns:
        List[float]: Haralickç‰¹å¾(å¯¹æ¯”åº¦ã€ç›¸å…³æ€§ã€èƒ½é‡ã€åŒè´¨æ€§)
    """
    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    rows, cols = glcm.shape
    mean_i = 0
    mean_j = 0

    # è®¡ç®—å‡å€¼
    for i in range(rows):
        for j in range(cols):
            mean_i += i * glcm[i, j]
            mean_j += j * glcm[i, j]

    # è®¡ç®—æ ‡å‡†å·®
    std_i = 0
    std_j = 0
    for i in range(rows):
        for j in range(cols):
            std_i += (i - mean_i)**2 * glcm[i, j]
            std_j += (j - mean_j)**2 * glcm[i, j]

    std_i = np.sqrt(std_i)
    std_j = np.sqrt(std_j)

    # åˆå§‹åŒ–ç‰¹å¾
    contrast = 0
    correlation = 0
    energy = 0
    homogeneity = 0

    # è®¡ç®—ç‰¹å¾
    for i in range(rows):
        for j in range(cols):
            contrast += (i - j)**2 * glcm[i, j]
            if std_i > 0 and std_j > 0:  # é˜²æ­¢é™¤é›¶
                correlation += ((i - mean_i) * (j - mean_j) * glcm[i, j]) / (std_i * std_j)
            energy += glcm[i, j]**2
            homogeneity += glcm[i, j] / (1 + (i - j)**2)

    return [contrast, correlation, energy, homogeneity]
```

## 3. ç»Ÿè®¡ç‰¹å¾åˆ†æ

### 3.1 ä¸€é˜¶ç»Ÿè®¡ç‰¹å¾

è¿™äº›ç‰¹å¾å°±åƒæ˜¯ç»™çº¹ç†åš"ä½“æ£€æŠ¥å‘Š"ï¼Œå‘Šè¯‰æˆ‘ä»¬çº¹ç†çš„åŸºæœ¬æƒ…å†µï¼š

1. å‡å€¼(Mean)ï¼šçº¹ç†çš„å¹³å‡ç°åº¦å€¼
   - å°±åƒæ˜¯åœ¨çœ‹"å¹³å‡èº«é«˜"
   - åæ˜ äº†çº¹ç†çš„æ•´ä½“äº®åº¦
   $$
   \mu = \frac{1}{N} \sum_{i=1}^N x_i
   $$

2. æ–¹å·®(Variance)ï¼šçº¹ç†çš„ç°åº¦å˜åŒ–ç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"èº«é«˜å·®å¼‚"
   - åæ˜ äº†çº¹ç†çš„å¯¹æ¯”åº¦
   $$
   \sigma^2 = \frac{1}{N} \sum_{i=1}^N (x_i - \mu)^2
   $$

3. ååº¦(Skewness)ï¼šçº¹ç†çš„ç°åº¦åˆ†å¸ƒåæ–œç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"èº«é«˜åˆ†å¸ƒæ˜¯å¦å¯¹ç§°"
   - åæ˜ äº†çº¹ç†çš„ä¸å¯¹ç§°æ€§
   $$
   \text{Skewness} = \frac{1}{N\sigma^3} \sum_{i=1}^N (x_i - \mu)^3
   $$

4. å³°åº¦(Kurtosis)ï¼šçº¹ç†çš„ç°åº¦åˆ†å¸ƒå°–é”ç¨‹åº¦
   - å°±åƒæ˜¯åœ¨çœ‹"èº«é«˜åˆ†å¸ƒæ˜¯å¦é›†ä¸­"
   - åæ˜ äº†çº¹ç†çš„å‡åŒ€æ€§
   $$
   \text{Kurtosis} = \frac{1}{N\sigma^4} \sum_{i=1}^N (x_i - \mu)^4 - 3
   $$

### 3.2 ä»£ç å®ç°

```cpp
// è®¡ç®—ç»Ÿè®¡ç‰¹å¾
vector<Mat> compute_statistical_features(const Mat& src, int window_size) {
    vector<Mat> features(4);  // å‡å€¼ã€æ–¹å·®ã€ååº¦ã€å³°åº¦
    for(auto& feat : features) {
        feat.create(src.size(), CV_32F);
    }

    int half_size = window_size / 2;

    #pragma omp parallel for collapse(2)
    for(int i = 0; i < src.rows; i++) {
        for(int j = 0; j < src.cols; j++) {
            // æå–å±€éƒ¨çª—å£
            Rect roi(
                max(0, j-half_size),
                max(0, i-half_size),
                min(window_size, src.cols-max(0,j-half_size)),
                min(window_size, src.rows-max(0,i-half_size))
            );
            Mat window = src(roi);

            // è®¡ç®—ç»Ÿè®¡ç‰¹å¾
            double mean = compute_mean(window);
            double variance = compute_variance(window, mean);
            double std_dev = sqrt(variance);
            double skewness = compute_skewness(window, mean, std_dev);
            double kurtosis = compute_kurtosis(window, mean, std_dev);

            // å­˜å‚¨ç»“æœ
            features[0].at<float>(i,j) = mean;
            features[1].at<float>(i,j) = variance;
            features[2].at<float>(i,j) = skewness;
            features[3].at<float>(i,j) = kurtosis;
        }
    }

    return features;
}

// è®¡ç®—å‡å€¼
double compute_mean(const Mat& window) {
    Scalar mean = cv::mean(window);
    return mean[0];
}

// è®¡ç®—æ–¹å·®
double compute_variance(const Mat& window, double mean) {
    double variance = 0;
    #pragma omp parallel for reduction(+:variance)
    for (int i = 0; i < window.rows; i++) {
        for (int j = 0; j < window.cols; j++) {
            double diff = window.at<uchar>(i,j) - mean;
            variance += diff * diff;
        }
    }
    return variance / (window.rows * window.cols);
}

// è®¡ç®—ååº¦
double compute_skewness(const Mat& window, double mean, double std_dev) {
    double skewness = 0;
    #pragma omp parallel for reduction(+:skewness)
    for (int i = 0; i < window.rows; i++) {
        for (int j = 0; j < window.cols; j++) {
            double diff = (window.at<uchar>(i,j) - mean) / std_dev;
            skewness += diff * diff * diff;
        }
    }
    return skewness / (window.rows * window.cols);
}

// è®¡ç®—å³°åº¦
double compute_kurtosis(const Mat& window, double mean, double std_dev) {
    double kurtosis = 0;
    #pragma omp parallel for reduction(+:kurtosis)
    for (int i = 0; i < window.rows; i++) {
        for (int j = 0; j < window.cols; j++) {
            double diff = (window.at<uchar>(i,j) - mean) / std_dev;
            kurtosis += diff * diff * diff * diff;
        }
    }
    return kurtosis / (window.rows * window.cols) - 3.0;
}
```

## 4. å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)

### 4.1 åŸºæœ¬åŸç†

LBPå°±åƒæ˜¯ç»™æ¯ä¸ªåƒç´ ç‚¹åš"äºŒè¿›åˆ¶ç¼–ç "ï¼å®ƒé€šè¿‡æ¯”è¾ƒä¸­å¿ƒåƒç´ ä¸å…¶é‚»åŸŸåƒç´ çš„å¤§å°å…³ç³»ï¼Œå¾—åˆ°ä¸€ä¸ªç‹¬ç‰¹çš„"èº«ä»½è¯å·ç "ã€‚

åŸºæœ¬æ­¥éª¤ï¼š
1. é€‰æ‹©ä¸€ä¸ªä¸­å¿ƒåƒç´ ï¼ˆå°±åƒé€‰ä¸€ä¸ª"ç­é•¿"ï¼‰
2. å°†å…¶ä¸é‚»åŸŸåƒç´ æ¯”è¾ƒï¼ˆå°±åƒ"ç­é•¿"å’Œ"åŒå­¦ä»¬"æ¯”èº«é«˜ï¼‰
3. ç”ŸæˆäºŒè¿›åˆ¶ç¼–ç ï¼ˆé«˜ä¸ªå­è®°1ï¼ŒçŸ®ä¸ªå­è®°0ï¼‰
4. è®¡ç®—åè¿›åˆ¶å€¼ï¼ˆæŠŠäºŒè¿›åˆ¶è½¬æ¢æˆåè¿›åˆ¶ï¼‰

ç¤ºæ„å›¾ï¼š
```
3  7  4    1  1  1    (128+64+32+
2  6  5 -> 0     1 -> 16+4) = 244
1  9  8    0  1  1
```

### 4.2 æ•°å­¦è¡¨è¾¾å¼

å¯¹äºåŠå¾„ä¸ºRçš„åœ†å½¢é‚»åŸŸä¸­çš„Pä¸ªé‡‡æ ·ç‚¹ï¼š

$$
LBP_{P,R} = \sum_{p=0}^{P-1} s(g_p - g_c)2^p
$$

å…¶ä¸­ï¼š
- $g_c$ æ˜¯ä¸­å¿ƒåƒç´ çš„ç°åº¦å€¼ï¼ˆ"ç­é•¿"çš„èº«é«˜ï¼‰
- $g_p$ æ˜¯é‚»åŸŸåƒç´ çš„ç°åº¦å€¼ï¼ˆ"åŒå­¦ä»¬"çš„èº«é«˜ï¼‰
- $s(x)$ æ˜¯é˜¶è·ƒå‡½æ•°ï¼ˆåˆ¤æ–­è°é«˜è°çŸ®ï¼‰ï¼š
$$
s(x) = \begin{cases}
1, & x \geq 0 \\
0, & x < 0
\end{cases}
$$

### 4.3 ä»£ç å®ç°

#### C++å®ç°
```cpp
Mat compute_lbp(const Mat& src, int radius, int neighbors) {
    Mat dst = Mat::zeros(src.size(), CV_8U);
    vector<int> center_points_x(neighbors);
    vector<int> center_points_y(neighbors);

    // Pre-compute sampling point coordinates
    for(int i = 0; i < neighbors; i++) {
        double angle = 2.0 * CV_PI * i / neighbors;
        center_points_x[i] = static_cast<int>(radius * cos(angle));
        center_points_y[i] = static_cast<int>(-radius * sin(angle));
    }

    #pragma omp parallel for
    for(int i = radius; i < src.rows-radius; i++) {
        for(int j = radius; j < src.cols-radius; j++) {
            uchar center = src.at<uchar>(i,j);
            uchar lbp_code = 0;

            for(int k = 0; k < neighbors; k++) {
                int x = j + center_points_x[k];
                int y = i + center_points_y[k];
                uchar neighbor = src.at<uchar>(y,x);

                lbp_code |= (neighbor > center) << k;
            }

            dst.at<uchar>(i,j) = lbp_code;
        }
    }

    return dst;
}
```

#### Pythonå®ç°
```python
def compute_lbp(img: np.ndarray, radius: int = 1,
               n_points: int = 8) -> np.ndarray:
    """è®¡ç®—å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)

    Args:
        img: è¾“å…¥å›¾åƒ
        radius: åŠå¾„
        n_points: é‡‡æ ·ç‚¹æ•°

    Returns:
        np.ndarray: LBPå›¾åƒ
    """
    # ç¡®ä¿å›¾åƒæ˜¯ç°åº¦å›¾
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # åˆ›å»ºè¾“å‡ºå›¾åƒ
    h, w = img.shape
    lbp = np.zeros((h, w), dtype=np.uint8)

    # è®¡ç®—é‡‡æ ·ç‚¹åæ ‡
    angles = np.linspace(0, 2*np.pi, n_points, endpoint=False)
    x = radius * np.cos(angles)
    y = radius * np.sin(angles)

    # å¯¹æ¯ä¸ªåƒç´ è®¡ç®—LBP
    for i in range(radius, h-radius):
        for j in range(radius, w-radius):
            center = img[i, j]
            pattern = 0

            for k in range(n_points):
                # åŒçº¿æ€§æ’å€¼è·å–é‡‡æ ·ç‚¹å€¼
                x1 = int(j + x[k])
                y1 = int(i + y[k])
                x2 = x1 + 1
                y2 = y1 + 1

                # è®¡ç®—æ’å€¼æƒé‡
                wx = j + x[k] - x1
                wy = i + y[k] - y1

                # åŒçº¿æ€§æ’å€¼
                val = (1-wx)*(1-wy)*img[y1,x1] + \
                      wx*(1-wy)*img[y1,x2] + \
                      (1-wx)*wy*img[y2,x1] + \
                      wx*wy*img[y2,x2]

                # æ›´æ–°LBPæ¨¡å¼
                pattern |= (val > center) << k

            lbp[i, j] = pattern

    return lbp
```

## 5. Gaborçº¹ç†ç‰¹å¾

### 5.1 Gaboræ»¤æ³¢å™¨

Gaboræ»¤æ³¢å™¨å°±åƒæ˜¯"çº¹ç†æ˜¾å¾®é•œ"ï¼å®ƒå¯ä»¥åœ¨ç‰¹å®šæ–¹å‘å’Œå°ºåº¦ä¸Šè§‚å¯Ÿçº¹ç†ç‰¹å¾ï¼Œå°±åƒæ˜¯åœ¨ç”¨ä¸åŒå€æ•°çš„æ˜¾å¾®é•œè§‚å¯Ÿç»†èƒã€‚

äºŒç»´Gaboræ»¤æ³¢å™¨çš„è¡¨è¾¾å¼ï¼š

$$
g(x,y) = \frac{1}{2\pi\sigma_x\sigma_y} \exp\left(-\frac{x'^2}{2\sigma_x^2}-\frac{y'^2}{2\sigma_y^2}\right)\cos(2\pi\frac{x'}{\lambda})
$$

å…¶ä¸­ï¼š
- $x' = x\cos\theta + y\sin\theta$ï¼ˆæ—‹è½¬åçš„xåæ ‡ï¼‰
- $y' = -x\sin\theta + y\cos\theta$ï¼ˆæ—‹è½¬åçš„yåæ ‡ï¼‰
- $\theta$ æ˜¯æ–¹å‘è§’ï¼ˆæ˜¾å¾®é•œçš„è§‚å¯Ÿè§’åº¦ï¼‰
- $\lambda$ æ˜¯æ³¢é•¿ï¼ˆè§‚å¯Ÿçš„ç²¾ç»†ç¨‹åº¦ï¼‰
- $\sigma_x$ å’Œ $\sigma_y$ æ˜¯é«˜æ–¯åŒ…ç»œçš„æ ‡å‡†å·®ï¼ˆè§‚å¯Ÿçš„èŒƒå›´å¤§å°ï¼‰

### 5.2 ç‰¹å¾æå–

1. ç”ŸæˆGaboræ»¤æ³¢å™¨ç»„ï¼ˆå‡†å¤‡ä¸åŒå€æ•°çš„"æ˜¾å¾®é•œ"ï¼‰
2. å¯¹å›¾åƒè¿›è¡Œæ»¤æ³¢ï¼ˆç”¨"æ˜¾å¾®é•œ"è§‚å¯Ÿå›¾åƒï¼‰
3. è®¡ç®—å“åº”çš„ç»Ÿè®¡ç‰¹å¾ï¼ˆè®°å½•è§‚å¯Ÿç»“æœï¼‰
4. ç»„åˆæˆç‰¹å¾å‘é‡ï¼ˆæ•´ç†è§‚å¯ŸæŠ¥å‘Šï¼‰

### 5.3 ä»£ç å®ç°

#### C++å®ç°
```cpp
vector<Mat> generate_gabor_filters(
    int ksize, double sigma, int theta,
    double lambda, double gamma, double psi) {

    vector<Mat> filters;
    filters.reserve(theta);

    double sigma_x = sigma;
    double sigma_y = sigma/gamma;

    int half_size = ksize/2;

    // Generate Gabor filters for different orientations
    for(int t = 0; t < theta; t++) {
        double theta_rad = t * CV_PI / theta;
        Mat kernel(ksize, ksize, CV_32F);

        #pragma omp parallel for
        for(int y = -half_size; y <= half_size; y++) {
            for(int x = -half_size; x <= half_size; x++) {
                // Rotation
                double x_theta = x*cos(theta_rad) + y*sin(theta_rad);
                double y_theta = -x*sin(theta_rad) + y*cos(theta_rad);

                // Gabor function
                double gaussian = exp(-0.5 * (x_theta*x_theta/(sigma_x*sigma_x) +
                                            y_theta*y_theta/(sigma_y*sigma_y)));
                double harmonic = cos(2*CV_PI*x_theta/lambda + psi);

                kernel.at<float>(y+half_size,x+half_size) = static_cast<float>(gaussian * harmonic);
            }
        }

        // Normalize
        kernel = kernel / sum(abs(kernel))[0];
        filters.push_back(kernel);
    }

    return filters;
}

vector<Mat> extract_gabor_features(
    const Mat& src,
    const vector<Mat>& filters) {

    vector<Mat> features;
    features.reserve(filters.size());

    Mat src_float;
    src.convertTo(src_float, CV_32F);

    // Apply convolution with each filter
    #pragma omp parallel for
    for(int i = 0; i < static_cast<int>(filters.size()); i++) {
        Mat response;
        filter2D(src_float, response, CV_32F, filters[i]);

        // Calculate magnitude
        Mat magnitude;
        magnitude = abs(response);

        #pragma omp critical
        features.push_back(magnitude);
    }

    return features;
}
```

#### Pythonå®ç°
```python
def compute_gabor_features(img: np.ndarray,
                          num_scales: int = 4,
                          num_orientations: int = 6) -> np.ndarray:
    """è®¡ç®—Gaborç‰¹å¾

    Args:
        img: è¾“å…¥å›¾åƒ
        num_scales: å°ºåº¦æ•°
        num_orientations: æ–¹å‘æ•°

    Returns:
        np.ndarray: Gaborç‰¹å¾å›¾
    """
    # ç¡®ä¿å›¾åƒæ˜¯ç°åº¦å›¾
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # åˆ›å»ºGaboræ»¤æ³¢å™¨ç»„
    filters = []
    for scale in range(num_scales):
        for orientation in range(num_orientations):
            # è®¡ç®—Gaborå‚æ•°
            theta = orientation * np.pi / num_orientations
            sigma = 2.0 * (2 ** scale)
            lambda_ = 4.0 * (2 ** scale)

            # åˆ›å»ºGaboræ»¤æ³¢å™¨
            kernel = cv2.getGaborKernel(
                (31, 31), sigma, theta, lambda_, 0.5, 0, ktype=cv2.CV_32F)

            filters.append(kernel)

    # åº”ç”¨Gaboræ»¤æ³¢å™¨
    features = []
    for kernel in filters:
        filtered = cv2.filter2D(img, cv2.CV_32F, kernel)
        features.append(filtered)

    return np.array(features)
```

## 6. çº¹ç†åˆ†ç±»

### 6.1 åŸºæœ¬åŸç†

çº¹ç†åˆ†ç±»å°±åƒæ˜¯ç»™ä¸åŒçš„"å¸ƒæ–™"è´´æ ‡ç­¾ï¼æˆ‘ä»¬éœ€è¦ï¼š
1. æå–ç‰¹å¾ï¼ˆæµ‹é‡å¸ƒæ–™çš„"ç‰¹å¾"ï¼‰
2. è®­ç»ƒåˆ†ç±»å™¨ï¼ˆå­¦ä¹ ä¸åŒå¸ƒæ–™çš„"ç‰¹ç‚¹"ï¼‰
3. é¢„æµ‹ç±»åˆ«ï¼ˆç»™æ–°å¸ƒæ–™"è´´æ ‡ç­¾"ï¼‰

### 6.2 ç‰¹å¾æå–å’Œé€‰æ‹©

1. GLCMç‰¹å¾ï¼ˆå¸ƒæ–™çš„"çº¹ç†è§„å¾‹"ï¼‰
2. LBPç‰¹å¾ï¼ˆå¸ƒæ–™çš„"å±€éƒ¨ç‰¹å¾"ï¼‰
3. Gaborç‰¹å¾ï¼ˆå¸ƒæ–™çš„"å¤šå°ºåº¦ç‰¹å¾"ï¼‰
4. ç»Ÿè®¡ç‰¹å¾ï¼ˆå¸ƒæ–™çš„"æ•´ä½“ç‰¹å¾"ï¼‰

### 6.3 åˆ†ç±»ç®—æ³•

#### 6.3.1 Kè¿‘é‚»(K-NN)

K-NNå°±åƒæ˜¯"ç‰©ä»¥ç±»èš"ï¼å®ƒé€šè¿‡æ‰¾åˆ°Kä¸ªæœ€ç›¸ä¼¼çš„æ ·æœ¬ï¼Œç”¨å®ƒä»¬çš„å¤šæ•°ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚

æ•°å­¦è¡¨è¾¾å¼ï¼š
$$
\hat{y} = \arg\max_{c} \sum_{i=1}^K I(y_i = c)
$$

å…¶ä¸­ï¼š
- $\hat{y}$ æ˜¯é¢„æµ‹çš„ç±»åˆ«
- $y_i$ æ˜¯ç¬¬iä¸ªè¿‘é‚»çš„ç±»åˆ«
- $I(\cdot)$ æ˜¯æŒ‡ç¤ºå‡½æ•°
- $c$ æ˜¯ç±»åˆ«æ ‡ç­¾

#### 6.3.2 æ”¯æŒå‘é‡æœº(SVM)

SVMå°±åƒæ˜¯"ç”»ä¸€æ¡çº¿"ï¼å®ƒè¯•å›¾æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„å†³ç­–è¾¹ç•Œï¼Œä½¿å¾—ä¸åŒç±»åˆ«çš„æ ·æœ¬è¢«æœ€å¤§é—´éš”åˆ†å¼€ã€‚

æ•°å­¦è¡¨è¾¾å¼ï¼š
$$
\min_{w,b} \frac{1}{2}\|w\|^2 + C\sum_{i=1}^n \xi_i
$$

çº¦æŸæ¡ä»¶ï¼š
$$
y_i(w^T x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0
$$

å…¶ä¸­ï¼š
- $w$ æ˜¯æ³•å‘é‡
- $b$ æ˜¯åç½®é¡¹
- $C$ æ˜¯æƒ©ç½šå‚æ•°
- $\xi_i$ æ˜¯æ¾å¼›å˜é‡

### 6.4 ä»£ç å®ç°

#### C++å®ç°
```cpp
// KNNåˆ†ç±»å™¨
class KNNClassifier {
private:
    std::vector<std::vector<float>> train_features;
    std::vector<int> train_labels;
    int k;

public:
    KNNClassifier(int k = 5) : k(k) {}

    void train(const std::vector<std::vector<float>>& features,
              const std::vector<int>& labels) {
        train_features = features;
        train_labels = labels;
    }

    int predict(const std::vector<float>& feature) {
        std::vector<std::pair<float, int>> distances;

        #pragma omp parallel for
        for(size_t i = 0; i < train_features.size(); i++) {
            float dist = 0;
            for(size_t j = 0; j < feature.size(); j++) {
                float diff = feature[j] - train_features[i][j];
                dist += diff * diff;
            }
            distances.push_back({std::sqrt(dist), train_labels[i]});
        }

        std::sort(distances.begin(), distances.end());

        std::vector<int> votes(k);
        for(int i = 0; i < k; i++) {
            votes[distances[i].second]++;
        }

        return std::max_element(votes.begin(), votes.end()) - votes.begin();
    }
};

// SVMåˆ†ç±»å™¨
class SVMClassifier {
private:
    std::vector<std::vector<float>> support_vectors;
    std::vector<float> weights;
    float bias;
    float learning_rate;
    int max_iterations;

public:
    SVMClassifier(float learning_rate = 0.001, int max_iterations = 1000)
        : learning_rate(learning_rate), max_iterations(max_iterations) {}

    void train(const std::vector<std::vector<float>>& features,
              const std::vector<int>& labels) {
        int n_samples = features.size();
        int n_features = features[0].size();

        weights.resize(n_features, 0);
        bias = 0;

        for(int iter = 0; iter < max_iterations; iter++) {
            float error = 0;

            #pragma omp parallel for reduction(+:error)
            for(int i = 0; i < n_samples; i++) {
                float prediction = 0;
                for(int j = 0; j < n_features; j++) {
                    prediction += weights[j] * features[i][j];
                }
                prediction += bias;

                float label = labels[i] * 2 - 1;  // è½¬æ¢ä¸º-1å’Œ1
                if(label * prediction < 1) {
                    error += 1 - label * prediction;

                    #pragma omp critical
                    {
                        for(int j = 0; j < n_features; j++) {
                            weights[j] += learning_rate * (label * features[i][j] - 0.01 * weights[j]);
                        }
                        bias += learning_rate * label;
                    }
                }
            }

            if(error == 0) break;
        }

        // ä¿å­˜æ”¯æŒå‘é‡
        for(int i = 0; i < n_samples; i++) {
            float prediction = 0;
            for(int j = 0; j < n_features; j++) {
                prediction += weights[j] * features[i][j];
            }
            prediction += bias;

            if(std::abs(prediction) < 1) {
                support_vectors.push_back(features[i]);
            }
        }
    }

    int predict(const std::vector<float>& feature) {
        float prediction = 0;
        for(size_t i = 0; i < feature.size(); i++) {
            prediction += weights[i] * feature[i];
        }
        prediction += bias;

        return prediction > 0 ? 1 : 0;
    }
};
```

#### Pythonå®ç°
```python
class KNNClassifier:
    """Kè¿‘é‚»åˆ†ç±»å™¨"""
    def __init__(self, k=5):
        self.k = k
        self.train_features = None
        self.train_labels = None

    def train(self, features, labels):
        """è®­ç»ƒæ¨¡å‹

        å‚æ•°:
            features: è®­ç»ƒç‰¹å¾
            labels: è®­ç»ƒæ ‡ç­¾
        """
        self.train_features = np.array(features)
        self.train_labels = np.array(labels)

    def predict(self, feature):
        """é¢„æµ‹å•ä¸ªæ ·æœ¬çš„ç±»åˆ«

        å‚æ•°:
            feature: è¾“å…¥ç‰¹å¾

        è¿”å›:
            predicted_label: é¢„æµ‹çš„ç±»åˆ«
        """
        # è®¡ç®—è·ç¦»
        distances = np.sqrt(np.sum((self.train_features - feature) ** 2, axis=1))

        # è·å–kä¸ªæœ€è¿‘é‚»çš„ç´¢å¼•
        k_indices = np.argsort(distances)[:self.k]

        # è·å–kä¸ªæœ€è¿‘é‚»çš„æ ‡ç­¾
        k_nearest_labels = self.train_labels[k_indices]

        # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ ‡ç­¾
        return np.bincount(k_nearest_labels).argmax()

class SVMClassifier:
    """æ”¯æŒå‘é‡æœºåˆ†ç±»å™¨"""
    def __init__(self, learning_rate=0.001, max_iterations=1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
        self.support_vectors = None

    def train(self, features, labels):
        """è®­ç»ƒæ¨¡å‹

        å‚æ•°:
            features: è®­ç»ƒç‰¹å¾
            labels: è®­ç»ƒæ ‡ç­¾
        """
        n_samples, n_features = np.array(features).shape

        # åˆå§‹åŒ–å‚æ•°
        self.weights = np.zeros(n_features)
        self.bias = 0

        # å°†æ ‡ç­¾è½¬æ¢ä¸º-1å’Œ1
        y = np.array(labels) * 2 - 1

        for _ in range(self.max_iterations):
            error = 0

            for i in range(n_samples):
                prediction = np.dot(self.weights, features[i]) + self.bias

                if y[i] * prediction < 1:
                    error += 1 - y[i] * prediction

                    # æ›´æ–°æƒé‡å’Œåç½®
                    self.weights += self.learning_rate * (y[i] * features[i] - 0.01 * self.weights)
                    self.bias += self.learning_rate * y[i]

            if error == 0:
                break

        # ä¿å­˜æ”¯æŒå‘é‡
        self.support_vectors = []
        for i in range(n_samples):
            prediction = np.dot(self.weights, features[i]) + self.bias
            if abs(prediction) < 1:
                self.support_vectors.append(features[i])

    def predict(self, feature):
        """é¢„æµ‹å•ä¸ªæ ·æœ¬çš„ç±»åˆ«

        å‚æ•°:
            feature: è¾“å…¥ç‰¹å¾

        è¿”å›:
            predicted_label: é¢„æµ‹çš„ç±»åˆ«
        """
        prediction = np.dot(self.weights, feature) + self.bias
        return 1 if prediction > 0 else 0
```

## 7. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 7.1 å¹¶è¡Œè®¡ç®—

1. ä½¿ç”¨OpenMPè¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼ˆå°±åƒ"å¤šçº¿ç¨‹è·‘æ­¥"ï¼‰
2. åˆç†è®¾ç½®çº¿ç¨‹æ•°ï¼ˆä¸è¦"äººå¤ªå¤šæŒ¤åœ¨ä¸€èµ·"ï¼‰
3. é¿å…çº¿ç¨‹ç«äº‰ï¼ˆä¸è¦"æŠ¢è·‘é“"ï¼‰

### 7.2 å†…å­˜ä¼˜åŒ–

1. ä½¿ç”¨è¿ç»­å†…å­˜ï¼ˆå°±åƒ"æ’å¥½é˜Ÿ"ï¼‰
2. é¿å…é¢‘ç¹çš„å†…å­˜åˆ†é…ï¼ˆä¸è¦"æ€»æ˜¯æ¬å®¶"ï¼‰
3. ä½¿ç”¨å†…å­˜æ± ï¼ˆå°±åƒ"æå‰å‡†å¤‡å¥½æˆ¿é—´"ï¼‰

### 7.3 ç®—æ³•ä¼˜åŒ–

1. ä½¿ç”¨æŸ¥æ‰¾è¡¨ï¼ˆå°±åƒ"æå‰èƒŒå¥½ç­”æ¡ˆ"ï¼‰
2. å‡å°‘é‡å¤è®¡ç®—ï¼ˆä¸è¦"é‡å¤åšåŒä¸€ä»¶äº‹"ï¼‰
3. ä½¿ç”¨SIMDæŒ‡ä»¤ï¼ˆå°±åƒ"ä¸€æ¬¡åšå¤šä»¶äº‹"ï¼‰

## 8. æ€»ç»“

çº¹ç†åˆ†æå°±åƒæ˜¯åœ¨ç»™å›¾åƒåš"æŒ‡çº¹è¯†åˆ«"ï¼Œæ¯ç§çº¹ç†éƒ½æœ‰å…¶ç‹¬ç‰¹çš„"æŒ‡çº¹"ï¼é€šè¿‡GLCMã€LBPå’ŒGaborç­‰æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°æå–å’Œåˆ†æè¿™äº›"æŒ‡çº¹"ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œéœ€è¦æ ¹æ®å…·ä½“åœºæ™¯é€‰æ‹©åˆé€‚çš„æ–¹æ³•ï¼Œå°±åƒé€‰æ‹©ä¸åŒçš„"æ˜¾å¾®é•œ"æ¥è§‚å¯Ÿä¸åŒçš„æ ·æœ¬ã€‚

è®°ä½ï¼šå¥½çš„çº¹ç†åˆ†æå°±åƒæ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„"çº¹ç†ä¾¦æ¢"ï¼Œèƒ½å¤Ÿä»å›¾åƒçš„ç»†èŠ‚ä¸­å‘ç°é‡è¦çš„çº¿ç´¢ï¼ğŸ”

## 9. å‚è€ƒèµ„æ–™

1. Haralick R M. Statistical and structural approaches to texture[J]. Proceedings of the IEEE, 1979
2. Ojala T, et al. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns[J]. IEEE TPAMI, 2002
3. OpenCVå®˜æ–¹æ–‡æ¡£: https://docs.opencv.org/
4. æ›´å¤šèµ„æº: [IP101é¡¹ç›®ä¸»é¡µ](https://github.com/GlimmerLab/IP101)