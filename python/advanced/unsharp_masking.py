"""
ğŸ–Œï¸ é”åŒ–çš„è‰ºæœ¯å“²å­¦ï¼šé’åŒ–è’™ç‰ˆç®—æ³•çš„Pythonå®ç°

è¿™ä¸ªæ¨¡å—å®ç°äº†å®Œæ•´çš„é’åŒ–è’™ç‰ˆé”åŒ–ç®—æ³•ï¼ŒåŒ…å«ï¼š
- åŸºç¡€é’åŒ–è’™ç‰ˆï¼šçº¯çœŸçš„é”åŒ–è‰ºæœ¯
- é˜ˆå€¼é’åŒ–è’™ç‰ˆï¼šæ™ºæ…§çš„é€‰æ‹©æ€§é”åŒ–
- è‡ªé€‚åº”é’åŒ–è’™ç‰ˆï¼šç¦…å¸ˆèˆ¬çš„è§‰å¯Ÿä¸æ…ˆæ‚²
- è¾¹ç¼˜ä¿æŠ¤åˆ†æï¼šå±•ç¤ºç®—æ³•çš„æ™ºæ…§
- äº¤äº’å¼æ¼”ç¤ºï¼šå®æ—¶ä½“éªŒé”åŒ–çš„é­”æ³•

ä½œè€…ï¼šGlimmerLab
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, Optional, Dict, Any, List
from dataclasses import dataclass
import math
import argparse
import os
from pathlib import Path
import time

@dataclass
class UnsharpMaskingParams:
    """ğŸ¨ é’åŒ–è’™ç‰ˆçš„è‰ºæœ¯é…ç½®å‚æ•°"""
    strength: float = 1.5      # é”åŒ–å¼ºåº¦ [0, 5]
    radius: float = 1.0        # æ¨¡ç³ŠåŠå¾„
    threshold: float = 10.0    # é”åŒ–é˜ˆå€¼ [0, 255]
    adaptive: bool = False     # æ˜¯å¦è‡ªé€‚åº”
    edge_protect: float = 0.5  # è¾¹ç¼˜ä¿æŠ¤ [0, 1]

    def __post_init__(self):
        """å‚æ•°æœ‰æ•ˆæ€§æ£€æŸ¥"""
        assert 0.0 <= self.strength <= 5.0, "é”åŒ–å¼ºåº¦å¿…é¡»åœ¨[0.0, 5.0]èŒƒå›´å†…"
        assert 0.0 < self.radius <= 10.0, "æ¨¡ç³ŠåŠå¾„å¿…é¡»åœ¨(0.0, 10.0]èŒƒå›´å†…"
        assert 0.0 <= self.threshold <= 255.0, "é”åŒ–é˜ˆå€¼å¿…é¡»åœ¨[0.0, 255.0]èŒƒå›´å†…"
        assert 0.0 <= self.edge_protect <= 1.0, "è¾¹ç¼˜ä¿æŠ¤å¿…é¡»åœ¨[0.0, 1.0]èŒƒå›´å†…"

class UnsharpMaskingArtist:
    """ğŸ–Œï¸ é’åŒ–è’™ç‰ˆè‰ºæœ¯å®¶ï¼šç”¨é€†å‘æ€ç»´åˆ›é€ é”åˆ©ä¹‹ç¾"""

    def __init__(self, params: Optional[UnsharpMaskingParams] = None):
        """
        ğŸŒŸ åˆå§‹åŒ–æˆ‘ä»¬çš„é”åŒ–è‰ºæœ¯å®¶
        æ¯ä¸ªå‚æ•°éƒ½æ˜¯åˆ›ä½œå·¥å…·ç®±ä¸­çš„ç”»ç¬”
        """
        self.params = params or UnsharpMaskingParams()

    def basic_unsharp_masking(self, image: np.ndarray,
                             strength: float = 1.5,
                             radius: float = 1.0) -> np.ndarray:
        """
        ğŸŒ± åŸºç¡€é’åŒ–è’™ç‰ˆï¼šçº¯çœŸçš„é”åŒ–è‰ºæœ¯

        å°±åƒå¹´è½»ç”»å®¶çš„ç¬¬ä¸€å¹…ä½œå“ï¼Œå……æ»¡çƒ­æƒ…ä½†ç¼ºä¹æŠ€å·§çš„å¤æ‚æ€§

        Args:
            image: ç­‰å¾…é”åŒ–çš„ç”»å¸ƒ
            strength: åˆ›ä½œçš„æ¿€æƒ…å¼ºåº¦
            radius: æ¨¡ç³Šæ¢¦å¢ƒçš„åŠå¾„

        Returns:
            é‡è·é”åˆ©çš„è‰ºæœ¯å“
        """
        if len(image.shape) != 3:
            raise ValueError("ğŸš« è¯·æä¾›å½©è‰²å›¾åƒï¼Œå°±åƒç”»å®¶éœ€è¦è°ƒè‰²æ¿ä¸€æ ·")

        # ğŸ¨ è½¬æ¢ä¸ºç²¾å¯†çš„æµ®ç‚¹ç”»å¸ƒ
        image_float = image.astype(np.float32)

        # ğŸ’­ ç”¨é«˜æ–¯çš„æ¸©æŸ”åˆ›é€ æ¨¡ç³Šçš„æ¢¦å¢ƒ
        # å°†radiusè½¬æ¢ä¸ºåˆé€‚çš„kernelå¤§å°
        kernel_size = max(int(2 * radius * 3), 3) | 1  # ç¡®ä¿æ˜¯å¥‡æ•°ä¸”è‡³å°‘ä¸º3
        blurred = cv2.GaussianBlur(image_float, (kernel_size, kernel_size), radius)

        # âš¡ è®¡ç®—ç°å®ä¸æ¢¦å¢ƒçš„å·®å¼‚â€”â€”ç»†èŠ‚çš„ç²¾é­‚
        detail_layer = image_float - blurred

        # âœ¨ å°†ç²¾é­‚æ³¨å…¥ç°å®ï¼Œåˆ›é€ è¶…è¶Šçš„ç¾
        sharpened = image_float + strength * detail_layer

        # ğŸ–¼ï¸ è£å‰ªåˆ°äººé—´å¯è§çš„è‰²å½©èŒƒå›´
        result = np.clip(sharpened, 0, 255).astype(np.uint8)

        return result

    def threshold_unsharp_masking(self, image: np.ndarray,
                                 strength: float = 1.5,
                                 radius: float = 1.0,
                                 threshold: float = 10.0) -> np.ndarray:
        """
        ğŸ¯ é˜ˆå€¼é’åŒ–è’™ç‰ˆï¼šæ™ºæ…§çš„é€‰æ‹©æ€§é”åŒ–

        å¦‚åŒæˆç†Ÿè‰ºæœ¯å®¶çŸ¥é“ä½•æ—¶ä¸‹é‡ç¬”ï¼Œä½•æ—¶è½»ææ·¡å†™

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: é”åŒ–å¼ºåº¦
            radius: æ¨¡ç³ŠåŠå¾„
            threshold: é”åŒ–é˜ˆå€¼

        Returns:
            æ™ºæ…§é”åŒ–çš„å›¾åƒ
        """
        image_float = image.astype(np.float32)

        # ğŸ’­ åˆ›é€ æ¸©æŸ”çš„æ¨¡ç³Šæ¢¦å¢ƒ
        kernel_size = max(int(2 * radius * 3), 3) | 1
        blurred = cv2.GaussianBlur(image_float, (kernel_size, kernel_size), radius)

        # âš¡ æå–ç»†èŠ‚ç²¾é­‚
        detail_layer = image_float - blurred

        # ğŸ­ åˆ›å»ºæ™ºæ…§çš„é¢å…·ï¼šåªå¯¹é‡è¦ç»†èŠ‚æ–½å±•é­”æ³•
        mask = np.zeros_like(detail_layer)

        for c in range(3):  # å¯¹æ¯ä¸ªé¢œè‰²é€šé“
            detail_abs = np.abs(detail_layer[:, :, c])

            # ğŸŒŸ å¯¹äºçœŸæ­£çš„ç»†èŠ‚ï¼Œå…¨åŠ›ä»¥èµ´
            strong_details = detail_abs > threshold
            mask[:, :, c][strong_details] = detail_layer[:, :, c][strong_details]

            # ğŸŒ™ å¯¹äºå¾®å¦™çš„å˜åŒ–ï¼Œæ¸©æŸ”æ¸å˜
            weak_details = detail_abs <= threshold
            if np.any(weak_details):
                scale = np.power(detail_abs[weak_details] / threshold, 2.0)
                mask[:, :, c][weak_details] = scale * detail_layer[:, :, c][weak_details]

        # ğŸ¨ åº”ç”¨æ™ºæ…§çš„é”åŒ–
        sharpened = image_float + strength * mask

        return np.clip(sharpened, 0, 255).astype(np.uint8)

    def adaptive_unsharp_masking(self, image: np.ndarray,
                                strength: float = 1.5,
                                radius: float = 1.0,
                                edge_protect: float = 0.5) -> np.ndarray:
        """
        ğŸ§˜ è‡ªé€‚åº”é’åŒ–è’™ç‰ˆï¼šç¦…å¸ˆèˆ¬çš„è§‰å¯Ÿä¸æ…ˆæ‚²

        èƒ½å¤Ÿæ„ŸçŸ¥å›¾åƒçš„å†…å®¹ï¼Œåœ¨éœ€è¦çš„åœ°æ–¹å‘åŠ›ï¼Œåœ¨è„†å¼±çš„åœ°æ–¹ä¿æŠ¤

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: é”åŒ–å¼ºåº¦
            radius: æ¨¡ç³ŠåŠå¾„
            edge_protect: è¾¹ç¼˜ä¿æŠ¤å¼ºåº¦

        Returns:
            è‡ªé€‚åº”é”åŒ–çš„å›¾åƒ
        """
        image_float = image.astype(np.float32)

        # ğŸ’­ åˆ›é€ æ¨¡ç³Šæ¢¦å¢ƒ
        kernel_size = max(int(2 * radius * 3), 3) | 1
        blurred = cv2.GaussianBlur(image_float, (kernel_size, kernel_size), radius)

        # âš¡ æå–ç»†èŠ‚ç²¾é­‚
        detail_layer = image_float - blurred

        # ğŸ” è§‰å¯Ÿè¾¹ç¼˜çš„å­˜åœ¨
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        sobel_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
        edges = np.sqrt(sobel_x**2 + sobel_y**2)

        # ğŸŒ¸ åˆ›å»ºæ…ˆæ‚²çš„æƒé‡ï¼šå¯¹è¾¹ç¼˜æ¸©æŸ”ä¿æŠ¤
        max_edge = np.max(edges)
        edge_norm = edges / max_edge if max_edge > 0 else edges

        # ğŸ•Šï¸ åœ¨å¼ºè¾¹ç¼˜å¤„å‡å°‘é”åŒ–ï¼Œåœ¨å¹³æ»‘åŒºåŸŸå¢å¼ºé”åŒ–
        protection_mask = 1.0 - edge_protect * np.power(edge_norm, 0.5)

        # ğŸ­ æ‰©å±•ä¸ºä¸‰é€šé“
        protection_mask_3d = np.stack([protection_mask] * 3, axis=-1)

        # ğŸ¨ åº”ç”¨è‡ªé€‚åº”é”åŒ–
        adaptive_detail = detail_layer * protection_mask_3d
        sharpened = image_float + strength * adaptive_detail

        return np.clip(sharpened, 0, 255).astype(np.uint8)

    def unsharp_masking(self, image: np.ndarray,
                       params: Optional[UnsharpMaskingParams] = None) -> np.ndarray:
        """
        ğŸŒŸ ç»Ÿä¸€çš„é’åŒ–è’™ç‰ˆæ¥å£ï¼šæ ¹æ®å‚æ•°é€‰æ‹©æœ€é€‚åˆçš„è‰ºæœ¯è¡¨è¾¾

        Args:
            image: è¾“å…¥å›¾åƒ
            params: é”åŒ–å‚æ•°é…ç½®

        Returns:
            é”åŒ–åçš„è‰ºæœ¯ä½œå“
        """
        p = params or self.params

        if p.adaptive:
            return self.adaptive_unsharp_masking(image, p.strength, p.radius, p.edge_protect)
        elif p.threshold > 0:
            return self.threshold_unsharp_masking(image, p.strength, p.radius, p.threshold)
        else:
            return self.basic_unsharp_masking(image, p.strength, p.radius)

    def multi_scale_unsharp_masking(self, image: np.ndarray,
                                   scales: List[float] = [0.5, 1.0, 2.0],
                                   weights: List[float] = [0.3, 0.5, 0.2]) -> np.ndarray:
        """
        ğŸŒ€ å¤šå°ºåº¦é’åŒ–è’™ç‰ˆï¼šå¦‚åŒç®¡å¼¦ä¹å›¢çš„å’Œè°æ¼”å¥

        åœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œé”åŒ–ï¼Œç„¶åèåˆç»“æœï¼Œå°±åƒéŸ³ä¹çš„å¤šå£°éƒ¨åˆå¥

        Args:
            image: è¾“å…¥å›¾åƒ
            scales: ä¸åŒçš„æ¨¡ç³ŠåŠå¾„å°ºåº¦
            weights: å„å°ºåº¦çš„æƒé‡

        Returns:
            å¤šå°ºåº¦èåˆçš„é”åŒ–ç»“æœ
        """
        if len(scales) != len(weights):
            raise ValueError("ğŸš« å°ºåº¦æ•°é‡å¿…é¡»ä¸æƒé‡æ•°é‡ç›¸åŒ¹é…")

        # å½’ä¸€åŒ–æƒé‡
        weights = np.array(weights)
        weights = weights / np.sum(weights)

        image_float = image.astype(np.float32)
        result = np.zeros_like(image_float)

        for scale, weight in zip(scales, weights):
            # ğŸµ åœ¨æ¯ä¸ªå°ºåº¦ä¸Šæ¼”å¥é”åŒ–çš„æ—‹å¾‹
            sharpened = self.basic_unsharp_masking(image, 1.5, scale)
            result += weight * sharpened.astype(np.float32)

        return np.clip(result, 0, 255).astype(np.uint8)

    def artistic_showcase(self, image: np.ndarray, save_path: Optional[str] = None) -> None:
        """
        ğŸ­ é”åŒ–è‰ºæœ¯å±•ç¤ºï¼šå±•ç°ä¸åŒé£æ ¼çš„é”åŒ–ç¾å­¦

        å¦‚åŒè‰ºæœ¯é¦†ä¸­çš„ä½œå“å±•è§ˆï¼Œå±•ç¤ºé”åŒ–çš„å¤šç§å¯èƒ½æ€§
        """
        print("ğŸ¨ å¼€å§‹åˆ›ä½œé”åŒ–è‰ºæœ¯ä½œå“...")

        # ğŸ¨ åˆ›å»ºä¸åŒé£æ ¼çš„é”åŒ–ä½œå“
        effects = {
            "ğŸ“· åŸå§‹æœ¦èƒ§": image,
            "ğŸŒ± çº¯çœŸé”åŒ–": self.basic_unsharp_masking(image, 1.5, 1.0),
            "ğŸ”¥ æ¿€æƒ…é”åŒ–": self.basic_unsharp_masking(image, 3.0, 1.5),
            "ğŸ¯ æ™ºæ…§é€‰æ‹©": self.threshold_unsharp_masking(image, 2.0, 1.0, 15.0),
            "ğŸ§˜ ç¦…å¸ˆå¢ƒç•Œ": self.adaptive_unsharp_masking(image, 2.0, 1.2, 0.7),
            "âš¡ ç»†èŠ‚å¼ºåŒ–": self.threshold_unsharp_masking(image, 2.5, 0.8, 5.0),
            "ğŸŒ€ å¤šå°ºåº¦": self.multi_scale_unsharp_masking(image),
            "ğŸ­ è‰ºæœ¯çº§": self.adaptive_unsharp_masking(image, 2.5, 1.5, 0.8)
        }

        # ğŸ–¼ï¸ åˆ›å»ºè‰ºæœ¯ç”»å»Š
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('ğŸ–Œï¸ é’åŒ–è’™ç‰ˆè‰ºæœ¯é¦†ï¼šé€†å‘æ€ç»´çš„é”åŒ–ç¾å­¦', fontsize=16, fontweight='bold')

        for i, (title, effect_image) in enumerate(effects.items()):
            row, col = i // 4, i % 4
            axes[row, col].imshow(cv2.cvtColor(effect_image, cv2.COLOR_BGR2RGB))
            axes[row, col].set_title(title, fontsize=11)
            axes[row, col].axis('off')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ é”åŒ–è‰ºæœ¯å±•ç¤ºå·²ä¿å­˜è‡³: {save_path}")

        plt.show()

    def edge_preservation_analysis(self, image: np.ndarray) -> None:
        """
        ğŸ” è¾¹ç¼˜ä¿æŠ¤åˆ†æï¼šå±•ç¤ºè‡ªé€‚åº”ç®—æ³•å¦‚ä½•æ™ºæ…§åœ°ä¿æŠ¤è¾¹ç¼˜
        """
        print("ğŸ” åˆ†æè¾¹ç¼˜ä¿æŠ¤æœºåˆ¶...")

        # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œè¾¹ç¼˜åˆ†æ
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # è®¡ç®—è¾¹ç¼˜å¼ºåº¦
        sobel_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
        edges = np.sqrt(sobel_x**2 + sobel_y**2)

        # è®¡ç®—ä¿æŠ¤æƒé‡
        max_edge = np.max(edges)
        edge_norm = edges / max_edge if max_edge > 0 else edges
        protection_mask = 1.0 - 0.7 * np.power(edge_norm, 0.5)

        # åº”ç”¨ä¸åŒçš„é”åŒ–æ–¹æ³•
        basic_sharp = self.basic_unsharp_masking(image, 2.5, 1.0)
        adaptive_sharp = self.adaptive_unsharp_masking(image, 2.5, 1.0, 0.7)

        # å¯è§†åŒ–å¯¹æ¯”
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('ğŸ” è¾¹ç¼˜ä¿æŠ¤æœºåˆ¶åˆ†æ', fontsize=14, fontweight='bold')

        axes[0, 0].imshow(gray, cmap='gray')
        axes[0, 0].set_title('ğŸ“· åŸå§‹å›¾åƒ')
        axes[0, 0].axis('off')

        axes[0, 1].imshow(edges, cmap='hot')
        axes[0, 1].set_title('âš¡ è¾¹ç¼˜æ£€æµ‹')
        axes[0, 1].axis('off')

        axes[0, 2].imshow(protection_mask, cmap='viridis')
        axes[0, 2].set_title('ğŸ›¡ï¸ ä¿æŠ¤æƒé‡')
        axes[0, 2].axis('off')

        axes[1, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        axes[1, 0].set_title('ğŸŒŸ åŸå§‹å›¾åƒ')
        axes[1, 0].axis('off')

        axes[1, 1].imshow(cv2.cvtColor(basic_sharp, cv2.COLOR_BGR2RGB))
        axes[1, 1].set_title('ğŸŒ± åŸºç¡€é”åŒ–')
        axes[1, 1].axis('off')

        axes[1, 2].imshow(cv2.cvtColor(adaptive_sharp, cv2.COLOR_BGR2RGB))
        axes[1, 2].set_title('ğŸ§˜ è‡ªé€‚åº”é”åŒ–')
        axes[1, 2].axis('off')

        plt.tight_layout()
        plt.show()

    def interactive_unsharp_masking(self, image: np.ndarray) -> None:
        """
        ğŸ® äº¤äº’å¼é’åŒ–è’™ç‰ˆï¼šå®æ—¶è°ƒæ•´å‚æ•°ä½“éªŒé”åŒ–é­”æ³•

        Args:
            image: è¾“å…¥å›¾åƒ
        """
        try:
            from matplotlib.widgets import Slider, RadioButtons
        except ImportError:
            print("âŒ éœ€è¦matplotlib.widgetsæ¨¡å—è¿›è¡Œäº¤äº’å¼æ¼”ç¤º")
            return

        fig = plt.figure(figsize=(16, 8))

        # åˆ›å»ºå­å›¾å¸ƒå±€
        ax_original = plt.subplot2grid((3, 4), (0, 0), rowspan=2, colspan=2)
        ax_result = plt.subplot2grid((3, 4), (0, 2), rowspan=2, colspan=2)
        ax_method = plt.subplot2grid((3, 4), (2, 0))

        # æ˜¾ç¤ºåŸå›¾
        ax_original.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        ax_original.set_title('ğŸ“· åŸå§‹å›¾åƒ', fontsize=12)
        ax_original.axis('off')

        # åˆå§‹æ•ˆæœ
        initial_result = self.basic_unsharp_masking(image, 1.5, 1.0)
        im_result = ax_result.imshow(cv2.cvtColor(initial_result, cv2.COLOR_BGR2RGB))
        ax_result.set_title('ğŸ–Œï¸ é”åŒ–æ•ˆæœ', fontsize=12)
        ax_result.axis('off')

        # æ–¹æ³•é€‰æ‹©
        methods = ['åŸºç¡€', 'é˜ˆå€¼', 'è‡ªé€‚åº”']
        radio = RadioButtons(ax_method, methods, active=0)
        ax_method.set_title('ğŸ­ é”åŒ–æ–¹æ³•')

        # åˆ›å»ºæ»‘å—
        ax_strength = plt.axes([0.15, 0.1, 0.2, 0.03])
        ax_radius = plt.axes([0.45, 0.1, 0.2, 0.03])
        ax_threshold = plt.axes([0.75, 0.1, 0.2, 0.03])
        ax_edge_protect = plt.axes([0.15, 0.05, 0.2, 0.03])

        slider_strength = Slider(ax_strength, 'å¼ºåº¦', 0.1, 5.0, valinit=1.5)
        slider_radius = Slider(ax_radius, 'åŠå¾„', 0.1, 5.0, valinit=1.0)
        slider_threshold = Slider(ax_threshold, 'é˜ˆå€¼', 0.0, 50.0, valinit=10.0)
        slider_edge_protect = Slider(ax_edge_protect, 'è¾¹ç¼˜ä¿æŠ¤', 0.0, 1.0, valinit=0.5)

        def update(_):
            """æ›´æ–°é”åŒ–æ•ˆæœ"""
            method = methods[methods.index(radio.value_selected)]
            strength = slider_strength.val
            radius = slider_radius.val
            threshold = slider_threshold.val
            edge_protect = slider_edge_protect.val

            if method == 'åŸºç¡€':
                result = self.basic_unsharp_masking(image, strength, radius)
            elif method == 'é˜ˆå€¼':
                result = self.threshold_unsharp_masking(image, strength, radius, threshold)
            else:  # è‡ªé€‚åº”
                result = self.adaptive_unsharp_masking(image, strength, radius, edge_protect)

            im_result.set_data(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
            ax_result.set_title(f'ğŸ–Œï¸ {method}é”åŒ–æ•ˆæœ')
            fig.canvas.draw()

        # ç»‘å®šäº‹ä»¶
        slider_strength.on_changed(update)
        slider_radius.on_changed(update)
        slider_threshold.on_changed(update)
        slider_edge_protect.on_changed(update)
        radio.on_clicked(update)

        plt.tight_layout()
        plt.show()

    def sharpness_metrics_analysis(self, image: np.ndarray) -> Dict[str, float]:
        """
        ğŸ“Š é”åº¦æŒ‡æ ‡åˆ†æï¼šé‡åŒ–è¯„ä¼°ä¸åŒé”åŒ–æ–¹æ³•çš„æ•ˆæœ

        Args:
            image: è¾“å…¥å›¾åƒ

        Returns:
            ä¸åŒæ–¹æ³•çš„é”åº¦æŒ‡æ ‡å­—å…¸
        """
        def calculate_sharpness(img: np.ndarray) -> float:
            """è®¡ç®—å›¾åƒé”åº¦ï¼ˆåŸºäºæ‹‰æ™®æ‹‰æ–¯ç®—å­æ–¹å·®ï¼‰"""
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            return laplacian.var()

        methods = {
            'åŸå§‹å›¾åƒ': image,
            'åŸºç¡€é”åŒ–': self.basic_unsharp_masking(image, 1.5, 1.0),
            'é˜ˆå€¼é”åŒ–': self.threshold_unsharp_masking(image, 1.5, 1.0, 10.0),
            'è‡ªé€‚åº”é”åŒ–': self.adaptive_unsharp_masking(image, 1.5, 1.0, 0.5),
            'å¤šå°ºåº¦é”åŒ–': self.multi_scale_unsharp_masking(image)
        }

        metrics = {}
        for name, img in methods.items():
            sharpness = calculate_sharpness(img)
            metrics[name] = sharpness
            print(f"ğŸ“ˆ {name}: é”åº¦å€¼ = {sharpness:.2f}")

        return metrics

    def performance_test(self, image_sizes: List[Tuple[int, int]] = None) -> Dict[str, float]:
        """
        âš¡ æ€§èƒ½æµ‹è¯•ï¼šè¯„ä¼°ä¸åŒé”åŒ–æ–¹æ³•çš„å¤„ç†é€Ÿåº¦

        Args:
            image_sizes: æµ‹è¯•çš„å›¾åƒå°ºå¯¸åˆ—è¡¨

        Returns:
            æ€§èƒ½æµ‹è¯•ç»“æœå­—å…¸
        """
        if image_sizes is None:
            image_sizes = [(256, 256), (512, 512), (1024, 1024)]

        results = {}

        print("ğŸš€ å¼€å§‹é”åŒ–æ€§èƒ½æµ‹è¯•...")
        print("=" * 60)

        for width, height in image_sizes:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)

            # æµ‹è¯•ä¸åŒæ–¹æ³•
            methods = {
                'åŸºç¡€é”åŒ–': lambda img: self.basic_unsharp_masking(img, 1.5, 1.0),
                'é˜ˆå€¼é”åŒ–': lambda img: self.threshold_unsharp_masking(img, 1.5, 1.0, 10.0),
                'è‡ªé€‚åº”é”åŒ–': lambda img: self.adaptive_unsharp_masking(img, 1.5, 1.0, 0.5)
            }

            print(f"ğŸ“Š å›¾åƒå°ºå¯¸: {width}x{height}")

            for method_name, method_func in methods.items():
                start_time = time.time()
                _ = method_func(test_image)
                processing_time = time.time() - start_time

                key = f"{method_name}_{width}x{height}"
                results[key] = processing_time

                print(f"  ğŸ–Œï¸ {method_name}: {processing_time:.3f}ç§’")

            print("-" * 40)

        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
        return results

def create_unsharp_masking_demo():
    """ğŸ¯ åˆ›å»ºé’åŒ–è’™ç‰ˆæ¼”ç¤ºç¨‹åº"""

    def process_image_interactive():
        """äº¤äº’å¼å›¾åƒå¤„ç†"""
        while True:
            print("\n" + "="*60)
            print("ğŸ–Œï¸ é’åŒ–è’™ç‰ˆè‰ºæœ¯å®¶ - äº¤äº’å¼æ¼”ç¤º")
            print("="*60)

            # è·å–å›¾åƒè·¯å¾„
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„ (æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
            if image_path.lower() == 'q':
                break

            if not os.path.exists(image_path):
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
                continue

            # åŠ è½½å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
                continue

            print(f"âœ… æˆåŠŸåŠ è½½å›¾åƒ: {image.shape}")

            # åˆ›å»ºé”åŒ–è‰ºæœ¯å®¶
            artist = UnsharpMaskingArtist()

            print("\nğŸ¨ è¯·é€‰æ‹©é”åŒ–æ–¹æ³•:")
            print("1. ğŸŒ± åŸºç¡€é”åŒ–")
            print("2. ğŸ¯ é˜ˆå€¼é”åŒ–")
            print("3. ğŸ§˜ è‡ªé€‚åº”é”åŒ–")
            print("4. ğŸŒ€ å¤šå°ºåº¦é”åŒ–")
            print("5. ğŸ­ è‰ºæœ¯å±•ç¤º")
            print("6. ğŸ” è¾¹ç¼˜ä¿æŠ¤åˆ†æ")
            print("7. ğŸ® äº¤äº’å¼è°ƒèŠ‚")
            print("8. ğŸ“Š é”åº¦åˆ†æ")

            choice = input("è¯·é€‰æ‹© (1-8): ").strip()

            try:
                if choice == '1':
                    strength = float(input("ğŸŒ± é”åŒ–å¼ºåº¦ [0.1-5.0, é»˜è®¤1.5]: ") or "1.5")
                    radius = float(input("ğŸŒ± æ¨¡ç³ŠåŠå¾„ [0.1-5.0, é»˜è®¤1.0]: ") or "1.0")
                    result = artist.basic_unsharp_masking(image, strength, radius)
                elif choice == '2':
                    strength = float(input("ğŸ¯ é”åŒ–å¼ºåº¦ [0.1-5.0, é»˜è®¤1.5]: ") or "1.5")
                    radius = float(input("ğŸ¯ æ¨¡ç³ŠåŠå¾„ [0.1-5.0, é»˜è®¤1.0]: ") or "1.0")
                    threshold = float(input("ğŸ¯ é”åŒ–é˜ˆå€¼ [0-50, é»˜è®¤10]: ") or "10")
                    result = artist.threshold_unsharp_masking(image, strength, radius, threshold)
                elif choice == '3':
                    strength = float(input("ğŸ§˜ é”åŒ–å¼ºåº¦ [0.1-5.0, é»˜è®¤1.5]: ") or "1.5")
                    radius = float(input("ğŸ§˜ æ¨¡ç³ŠåŠå¾„ [0.1-5.0, é»˜è®¤1.0]: ") or "1.0")
                    edge_protect = float(input("ğŸ§˜ è¾¹ç¼˜ä¿æŠ¤ [0-1, é»˜è®¤0.5]: ") or "0.5")
                    result = artist.adaptive_unsharp_masking(image, strength, radius, edge_protect)
                elif choice == '4':
                    result = artist.multi_scale_unsharp_masking(image)
                elif choice == '5':
                    artist.artistic_showcase(image)
                    continue
                elif choice == '6':
                    artist.edge_preservation_analysis(image)
                    continue
                elif choice == '7':
                    artist.interactive_unsharp_masking(image)
                    continue
                elif choice == '8':
                    artist.sharpness_metrics_analysis(image)
                    continue
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
                    continue

                # æ˜¾ç¤ºç»“æœ
                comparison = np.hstack([image, result])
                cv2.imshow("Unsharp Masking (Original | Sharpened)", comparison)
                cv2.waitKey(0)
                cv2.destroyAllWindows()

                # è¯¢é—®æ˜¯å¦ä¿å­˜
                save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜ç»“æœ? (y/n): ").strip().lower()
                if save_choice == 'y':
                    output_path = input("ğŸ“ è¾“å…¥ä¿å­˜è·¯å¾„ (é»˜è®¤: sharpened_result.jpg): ").strip() or "sharpened_result.jpg"
                    cv2.imwrite(output_path, result)
                    print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {output_path}")

            except ValueError:
                print("âŒ å‚æ•°æ ¼å¼é”™è¯¯")
            except Exception as e:
                print(f"âŒ å¤„ç†å‡ºé”™: {e}")

    def batch_process_demo():
        """æ‰¹é‡å¤„ç†æ¼”ç¤º"""
        print("\n" + "="*60)
        print("ğŸš€ æ‰¹é‡é’åŒ–è’™ç‰ˆå¤„ç†æ¼”ç¤º")
        print("="*60)

        input_dir = input("ğŸ“ è¾“å…¥å›¾åƒç›®å½•è·¯å¾„: ").strip()
        if not os.path.exists(input_dir):
            print("âŒ ç›®å½•ä¸å­˜åœ¨")
            return

        output_dir = input("ğŸ“ è¾“å‡ºç›®å½•è·¯å¾„: ").strip() or "sharpened_results"
        os.makedirs(output_dir, exist_ok=True)

        # è·å–å›¾åƒæ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = [f for f in os.listdir(input_dir)
                      if Path(f).suffix.lower() in image_extensions]

        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return

        print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")

        # åˆ›å»ºé”åŒ–è‰ºæœ¯å®¶
        artist = UnsharpMaskingArtist()

        # æ‰¹é‡å¤„ç†
        for i, filename in enumerate(image_files):
            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(output_dir, f"sharpened_{filename}")

            print(f"ğŸ¨ å¤„ç† ({i+1}/{len(image_files)}): {filename}")

            image = cv2.imread(input_path)
            if image is not None:
                result = artist.adaptive_unsharp_masking(image, 1.8, 1.2, 0.6)
                cv2.imwrite(output_path, result)
                print(f"âœ… å·²ä¿å­˜: {output_path}")
            else:
                print(f"âŒ æ— æ³•è¯»å–: {filename}")

        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")

    # ä¸»èœå•
    while True:
        print("\n" + "="*70)
        print("ğŸ–Œï¸ é’åŒ–è’™ç‰ˆè‰ºæœ¯å®¶ - é€†å‘æ€ç»´çš„é”åŒ–ç¾å­¦")
        print("="*70)
        print("1. ğŸ“· äº¤äº’å¼å•å›¾å¤„ç†")
        print("2. ğŸš€ æ‰¹é‡å›¾åƒå¤„ç†")
        print("3. ğŸ­ è‰ºæœ¯æ•ˆæœå±•ç¤º")
        print("4. ğŸ® äº¤äº’å¼å‚æ•°è°ƒèŠ‚")
        print("5. ğŸ“Š æ€§èƒ½æµ‹è¯•")
        print("6. ğŸ” é”åº¦åˆ†æ")
        print("0. ğŸ‘‹ é€€å‡ºç¨‹åº")
        print("="*70)

        choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (0-6): ").strip()

        if choice == '0':
            print("ğŸ‘‹ æ„Ÿè°¢ä½“éªŒé’åŒ–è’™ç‰ˆè‰ºæœ¯å®¶ï¼")
            print("æ„¿ä½ çš„å›¾åƒå¦‚é”åŒ–åèˆ¬æ¸…æ™°ç¾ä¸½ï¼ âœ¨")
            break
        elif choice == '1':
            process_image_interactive()
        elif choice == '2':
            batch_process_demo()
        elif choice == '3':
            image_path = input("ğŸ“· è¯·è¾“å…¥æµ‹è¯•å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = UnsharpMaskingArtist()
                    artist.artistic_showcase(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '4':
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = UnsharpMaskingArtist()
                    artist.interactive_unsharp_masking(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '5':
            artist = UnsharpMaskingArtist()
            artist.performance_test()
        elif choice == '6':
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = UnsharpMaskingArtist()
                    artist.sharpness_metrics_analysis(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def main():
    """ğŸŒŸ ä¸»å‡½æ•°ï¼šå±•ç¤ºé’åŒ–è’™ç‰ˆçš„è‰ºæœ¯é­…åŠ›"""
    parser = argparse.ArgumentParser(description="ğŸ–Œï¸ é’åŒ–è’™ç‰ˆ - é€†å‘æ€ç»´çš„é”åŒ–è‰ºæœ¯")
    parser.add_argument("--input", "-i", type=str, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", type=str, help="è¾“å‡ºå›¾åƒè·¯å¾„")
    parser.add_argument("--method", "-m", type=str, default="basic",
                       choices=["basic", "threshold", "adaptive", "multiscale"],
                       help="é”åŒ–æ–¹æ³•")
    parser.add_argument("--strength", "-s", type=float, default=1.5, help="é”åŒ–å¼ºåº¦ (0.1-5.0)")
    parser.add_argument("--radius", "-r", type=float, default=1.0, help="æ¨¡ç³ŠåŠå¾„ (0.1-5.0)")
    parser.add_argument("--threshold", "-t", type=float, default=10.0, help="é”åŒ–é˜ˆå€¼ (0-50)")
    parser.add_argument("--edge-protect", "-e", type=float, default=0.5, help="è¾¹ç¼˜ä¿æŠ¤ (0-1)")
    parser.add_argument("--demo", action="store_true", help="å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")
    parser.add_argument("--showcase", action="store_true", help="æ˜¾ç¤ºè‰ºæœ¯å±•ç¤º")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼å‚æ•°è°ƒèŠ‚")
    parser.add_argument("--analysis", action="store_true", help="é”åº¦åˆ†æ")
    parser.add_argument("--performance", action="store_true", help="è¿è¡Œæ€§èƒ½æµ‹è¯•")

    args = parser.parse_args()

    if args.demo:
        create_unsharp_masking_demo()
        return

    if not args.input:
        print("ğŸš« è¯·æä¾›è¾“å…¥å›¾åƒè·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --demo å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")
        print("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹: python unsharp_masking.py -i image.jpg -o result.jpg")
        print("ğŸ’¡ æ¼”ç¤ºæ¨¡å¼: python unsharp_masking.py --demo")
        return

    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return

    # åŠ è½½å›¾åƒ
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {args.input}")
        return

    print(f"âœ… æˆåŠŸåŠ è½½å›¾åƒ: {image.shape}")

    # åˆ›å»ºé”åŒ–è‰ºæœ¯å®¶
    artist = UnsharpMaskingArtist()

    if args.performance:
        # æ€§èƒ½æµ‹è¯•
        artist.performance_test()
        return

    if args.showcase:
        # è‰ºæœ¯å±•ç¤º
        save_path = args.output.replace('.jpg', '_showcase.png') if args.output else None
        artist.artistic_showcase(image, save_path)
        return

    if args.interactive:
        # äº¤äº’å¼è°ƒèŠ‚
        artist.interactive_unsharp_masking(image)
        return

    if args.analysis:
        # é”åº¦åˆ†æ
        artist.sharpness_metrics_analysis(image)
        return

    # åº”ç”¨æŒ‡å®šçš„é”åŒ–æ–¹æ³•
    print(f"ğŸ¨ åº”ç”¨{args.method}é”åŒ–...")

    if args.method == "basic":
        result = artist.basic_unsharp_masking(image, args.strength, args.radius)
    elif args.method == "threshold":
        result = artist.threshold_unsharp_masking(image, args.strength, args.radius, args.threshold)
    elif args.method == "adaptive":
        result = artist.adaptive_unsharp_masking(image, args.strength, args.radius, args.edge_protect)
    elif args.method == "multiscale":
        result = artist.multi_scale_unsharp_masking(image)

    if args.output:
        cv2.imwrite(args.output, result)
        print(f"âœ… é”åŒ–è‰ºæœ¯ä½œå“å·²ä¿å­˜è‡³: {args.output}")
    else:
        # æ˜¾ç¤ºå¯¹æ¯”
        comparison = np.hstack([image, result])
        cv2.imshow("Unsharp Masking (Original | Sharpened)", comparison)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()