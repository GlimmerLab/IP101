"""
ğŸŒŠ è¿åŠ¨çš„è¯—æ„ï¼šè¿åŠ¨æ¨¡ç³Šç®—æ³•çš„æ—¶é—´è‰ºæœ¯Pythonå®ç°

è¿™ä¸ªæ¨¡å—å®ç°äº†å®Œæ•´çš„è¿åŠ¨æ¨¡ç³Šç®—æ³•ï¼ŒåŒ…å«ï¼š
- æ–¹å‘æ€§è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒç–¾é£ä¸­çš„è‰åŸ
- å¾„å‘è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒæ¶Ÿæ¼ªå‘å››å‘¨æ‰©æ•£
- æ—‹è½¬è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒèˆè€…æ—‹è½¬çš„ä¼˜ç¾å¼§çº¿
- ç¼©æ”¾è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒæ—¶é—´éš§é“çš„è§†è§‰ä½“éªŒ
- äº¤äº’å¼æ¼”ç¤ºï¼šå®æ—¶ä½“éªŒæ—¶é—´çš„é­”æ³•
- æ€§èƒ½æµ‹è¯•ï¼šè¯„ä¼°ä¸åŒæ–¹æ³•çš„æ•ˆç‡

ä½œè€…ï¼šGlimmerLab
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, Optional, Dict, Any, List
from dataclasses import dataclass
import math
import argparse
import os
from pathlib import Path
import time

@dataclass
class MotionBlurParams:
    """ğŸ¨ è¿åŠ¨æ¨¡ç³Šçš„è‰ºæœ¯é…ç½®å‚æ•°"""
    size: int = 15              # æ¨¡ç³Šæ ¸å¤§å°
    angle: float = 45.0         # æ¨¡ç³Šæ–¹å‘è§’åº¦ (0-360åº¦)
    strength: float = 1.0       # æ¨¡ç³Šå¼ºåº¦ (0-1)
    motion_type: str = "linear" # è¿åŠ¨ç±»å‹ ("linear", "radial", "rotational", "zoom")

    def __post_init__(self):
        """å‚æ•°æœ‰æ•ˆæ€§æ£€æŸ¥"""
        assert self.size >= 3, "æ¨¡ç³Šæ ¸å¤§å°å¿…é¡» >= 3"
        assert 0.0 <= self.angle <= 360.0, "è§’åº¦å¿…é¡»åœ¨[0, 360]èŒƒå›´å†…"
        assert 0.0 <= self.strength <= 2.0, "å¼ºåº¦å¿…é¡»åœ¨[0, 2.0]èŒƒå›´å†…"
        assert self.motion_type in ["linear", "radial", "rotational", "zoom"], "æ— æ•ˆçš„è¿åŠ¨ç±»å‹"

class MotionBlurArtist:
    """ğŸŒŠ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶ï¼šç”¨æ—¶é—´çš„ç”»ç¬”åˆ›é€ åŠ¨æ„Ÿä¸–ç•Œ"""

    def __init__(self, params: Optional[MotionBlurParams] = None):
        """
        ğŸŒŸ åˆå§‹åŒ–æˆ‘ä»¬çš„æ—¶é—´è‰ºæœ¯å®¶
        æ¯ä¸ªå‚æ•°éƒ½æ˜¯æ—¶é—´é­”æ³•çš„å’’è¯­
        """
        self.params = params or MotionBlurParams()

    def create_motion_kernel(self, size: int, angle: float) -> np.ndarray:
        """
        ğŸ–Œï¸ åˆ›é€ è¿åŠ¨çš„ç¬”è§¦ï¼šå°†æ–¹å‘è½¬åŒ–ä¸ºæ•°å­¦çš„è¯—ç¯‡

        å°±åƒç”»å®¶é€‰æ‹©ç¬”è§¦çš„æ–¹å‘æ¥è¡¨ç°é£çš„æµåŠ¨

        Args:
            size: ç¬”è§¦çš„é•¿åº¦ï¼Œå†³å®šäº†è¿åŠ¨çš„è·ç¦»
            angle: ç¬”è§¦çš„æ–¹å‘ï¼Œè¡¨è¾¾ç€è¿åŠ¨çš„æ„å›¾

        Returns:
            ä¸€ä¸ªè•´å«æ—¶é—´æ™ºæ…§çš„è¿åŠ¨æ ¸
        """
        # ğŸ¨ ç¡®ä¿æ ¸å¤§å°ä¸ºå¥‡æ•°ï¼Œå¦‚åŒè‰ºæœ¯éœ€è¦å¹³è¡¡
        if size % 2 == 0:
            size += 1

        kernel = np.zeros((size, size), dtype=np.float32)

        # ğŸŒŸ å°†è§’åº¦è½¬æ¢ä¸ºå¼§åº¦ï¼Œè¿›å…¥æ•°å­¦çš„çº¯å‡€ä¸–ç•Œ
        radian_angle = math.radians(angle)

        # ğŸ¯ è®¡ç®—ä¸­å¿ƒç‚¹ï¼Œæ‰€æœ‰è¿åŠ¨çš„èµ·ç‚¹
        center_x, center_y = size // 2, size // 2

        # ğŸ§­ è®¡ç®—æ–¹å‘å‘é‡ï¼Œå¦‚åŒæŒ‡å—é’ˆçš„æŒ‡å‘
        dx = math.cos(radian_angle)
        dy = math.sin(radian_angle)

        # âœ¨ åœ¨æ•°å­¦ç”»å¸ƒä¸Šç»˜åˆ¶æ—¶é—´çš„è½¨è¿¹
        norm_factor = 0.0

        for i in range(-size//2, size//2 + 1):
            x = int(round(center_x + i * dx))
            y = int(round(center_y + i * dy))

            if 0 <= x < size and 0 <= y < size:
                kernel[y, x] = 1.0
                norm_factor += 1.0

        # ğŸ­ å½’ä¸€åŒ–ï¼šä¿æŒèƒ½é‡çš„å¹³è¡¡
        if norm_factor > 0:
            kernel /= norm_factor

        return kernel

    def directional_motion_blur(self, image: np.ndarray,
                               size: int = 15,
                               angle: float = 45.0,
                               strength: float = 1.0) -> np.ndarray:
        """
        ğŸƒâ€â™‚ï¸ æ–¹å‘æ€§è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒç–¾é£ä¸­çš„è‰åŸ

        Args:
            image: é™æ­¢çš„ç¬é—´ï¼Œç­‰å¾…æ—¶é—´çš„é­”æ³•
            size: è¿åŠ¨çš„è·ç¦»
            angle: è¿åŠ¨çš„æ–¹å‘
            strength: æ—¶é—´çš„å¼ºåº¦

        Returns:
            å……æ»¡åŠ¨æ„Ÿçš„è‰ºæœ¯ä½œå“
        """
        if len(image.shape) != 3:
            raise ValueError("ğŸš« è¯·æä¾›å½©è‰²å›¾åƒï¼Œå°±åƒç”Ÿæ´»éœ€è¦è‰²å½©ä¸€æ ·")

        # ğŸ–Œï¸ åˆ›é€ è¿åŠ¨çš„ç¬”è§¦
        kernel = self.create_motion_kernel(size, angle)

        # ğŸ¨ ç”¨è¿åŠ¨çš„ç¬”è§¦ä¸ºå›¾åƒæ³¨å…¥æ—¶é—´çš„æ´»åŠ›
        blurred = cv2.filter2D(image, -1, kernel)

        # ğŸŒˆ å¦‚æœéœ€è¦ï¼Œä¸åŸå›¾æ··åˆï¼Œåˆ›é€ æ°åˆ°å¥½å¤„çš„åŠ¨æ„Ÿ
        if abs(strength - 1.0) > 1e-6:
            result = cv2.addWeighted(image, 1.0 - strength, blurred, strength, 0)
            return result

        return blurred

    def radial_motion_blur(self, image: np.ndarray,
                          strength: float = 0.5,
                          center: Optional[Tuple[float, float]] = None) -> np.ndarray:
        """
        ğŸŒ€ å¾„å‘è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒæ¶Ÿæ¼ªå‘å››å‘¨æ‰©æ•£

        åˆ›é€ ä»ä¸­å¿ƒç‚¹å‘å¤–æ‰©æ•£çš„åŠ¨æ„Ÿæ•ˆæœ

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: æ‰©æ•£çš„å¼ºåº¦
            center: æ¶Ÿæ¼ªçš„ä¸­å¿ƒç‚¹

        Returns:
            å¸¦æœ‰å¾„å‘åŠ¨æ„Ÿçš„å›¾åƒ
        """
        h, w = image.shape[:2]

        # ğŸ¯ ç¡®å®šæ‰©æ•£çš„ä¸­å¿ƒ
        if center is None:
            center_x, center_y = w // 2, h // 2
        else:
            center_x, center_y = center

        # ğŸŒŠ é‡‡æ ·æ•°ï¼šæ¶Ÿæ¼ªçš„åœˆæ•°
        num_samples = 15
        step = strength / (num_samples - 1) if num_samples > 1 else 0

        # ğŸ¨ åˆ›é€ ç©ºç™½çš„ç”»å¸ƒ
        result = np.zeros_like(image, dtype=np.float64)
        total_weight = 0.0

        # ğŸŒŸ ç»˜åˆ¶æ¯ä¸€åœˆæ¶Ÿæ¼ª
        for i in range(num_samples):
            # ğŸ’« è®¡ç®—ç¼©æ”¾ç³»æ•°
            scale = 1.0 - step * i
            weight = 1.0 / num_samples
            total_weight += weight

            # ğŸ­ åˆ›å»ºä»¿å°„å˜æ¢çŸ©é˜µ
            M = np.float32([
                [scale, 0, center_x * (1 - scale)],
                [0, scale, center_y * (1 - scale)]
            ])

            # ğŸŒˆ åº”ç”¨å˜æ¢
            transformed = cv2.warpAffine(image, M, (w, h),
                                       flags=cv2.INTER_LINEAR,
                                       borderMode=cv2.BORDER_REPLICATE)

            # âœ¨ ç´¯ç§¯åˆ°æœ€ç»ˆç»“æœ
            result += weight * transformed.astype(np.float64)

        # âš–ï¸ ç¡®ä¿å®Œç¾çš„å¹³è¡¡
        return np.clip(result, 0, 255).astype(np.uint8)

    def rotational_motion_blur(self, image: np.ndarray,
                              strength: float = 0.5,
                              center: Optional[Tuple[float, float]] = None) -> np.ndarray:
        """
        ğŸŒªï¸ æ—‹è½¬è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒèˆè€…æ—‹è½¬çš„ä¼˜ç¾å¼§çº¿

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: æ—‹è½¬çš„å¼ºåº¦
            center: æ—‹è½¬çš„ä¸­å¿ƒ

        Returns:
            å¸¦æœ‰æ—‹è½¬åŠ¨æ„Ÿçš„å›¾åƒ
        """
        h, w = image.shape[:2]

        # ğŸ’ƒ ç¡®å®šæ—‹è½¬çš„ä¸­å¿ƒ
        if center is None:
            center_point = (w // 2, h // 2)
        else:
            center_point = center

        # ğŸµ é‡‡æ ·æ•°å’Œè§’åº¦èŒƒå›´
        num_samples = 15
        max_angle = 30.0 * strength
        angle_step = max_angle / (num_samples - 1) if num_samples > 1 else 0

        # ğŸ¨ åˆ›é€ ç©ºç™½ç”»å¸ƒ
        result = np.zeros_like(image, dtype=np.float64)
        total_weight = 0.0

        # ğŸŒ€ åˆ›é€ æ—‹è½¬çš„éŸµå¾‹
        for i in range(num_samples):
            # ğŸŒŸ è®¡ç®—æ—‹è½¬è§’åº¦
            angle = -max_angle / 2.0 + i * angle_step
            weight = 1.0 / num_samples
            total_weight += weight

            # ğŸ­ åˆ›å»ºæ—‹è½¬çŸ©é˜µ
            M = cv2.getRotationMatrix2D(center_point, angle, 1.0)

            # ğŸ’« åº”ç”¨æ—‹è½¬
            rotated = cv2.warpAffine(image, M, (w, h),
                                   flags=cv2.INTER_LINEAR,
                                   borderMode=cv2.BORDER_REPLICATE)

            # ğŸŒˆ å åŠ åˆ°ç»“æœ
            result += weight * rotated.astype(np.float64)

        return np.clip(result, 0, 255).astype(np.uint8)

    def zoom_motion_blur(self, image: np.ndarray,
                        strength: float = 0.5,
                        center: Optional[Tuple[float, float]] = None) -> np.ndarray:
        """
        ğŸ¯ ç¼©æ”¾è¿åŠ¨æ¨¡ç³Šï¼šå¦‚åŒæ—¶é—´éš§é“çš„è§†è§‰ä½“éªŒ

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: ç¼©æ”¾çš„å¼ºåº¦
            center: ç¼©æ”¾çš„ä¸­å¿ƒ

        Returns:
            å¸¦æœ‰ç¼©æ”¾åŠ¨æ„Ÿçš„å›¾åƒ
        """
        h, w = image.shape[:2]

        # ğŸ¯ ç¡®å®šç¼©æ”¾çš„ç„¦ç‚¹
        if center is None:
            center_x, center_y = w // 2, h // 2
        else:
            center_x, center_y = center

        # ğŸŒŸ é‡‡æ ·å‚æ•°
        num_samples = 15
        max_scale_delta = 0.4 * strength
        scale_step = max_scale_delta / (num_samples - 1) if num_samples > 1 else 0

        # ğŸ¨ åˆ›é€ ç©ºç™½ç”»å¸ƒ
        result = np.zeros_like(image, dtype=np.float64)
        total_weight = 0.0

        # ğŸ¬ åˆ›é€ ç”µå½±èˆ¬çš„ç¼©æ”¾æ•ˆæœ
        for i in range(num_samples):
            # ğŸ“ è®¡ç®—ç¼©æ”¾ç³»æ•°
            scale = 1.0 - max_scale_delta / 2.0 + i * scale_step
            weight = 1.0 / num_samples
            total_weight += weight

            # ğŸ­ åˆ›å»ºç¼©æ”¾å˜æ¢çŸ©é˜µ
            M = np.float32([
                [scale, 0, center_x * (1 - scale)],
                [0, scale, center_y * (1 - scale)]
            ])

            # ğŸŒ€ åº”ç”¨ç¼©æ”¾å˜æ¢
            scaled = cv2.warpAffine(image, M, (w, h),
                                  flags=cv2.INTER_LINEAR,
                                  borderMode=cv2.BORDER_REPLICATE)

            # âœ¨ ç´¯ç§¯æ•ˆæœ
            result += weight * scaled.astype(np.float64)

        return np.clip(result, 0, 255).astype(np.uint8)

    def motion_blur(self, image: np.ndarray,
                   params: Optional[MotionBlurParams] = None) -> np.ndarray:
        """
        ğŸŒŠ ç»Ÿä¸€çš„è¿åŠ¨æ¨¡ç³Šæ¥å£ï¼šæ ¹æ®å‚æ•°é€‰æ‹©æ—¶é—´çš„è‰ºæœ¯è¡¨è¾¾

        Args:
            image: è¾“å…¥å›¾åƒ
            params: è¿åŠ¨æ¨¡ç³Šå‚æ•°é…ç½®

        Returns:
            å……æ»¡æ—¶é—´é­”æ³•çš„è‰ºæœ¯ä½œå“
        """
        p = params or self.params

        if p.motion_type == "linear":
            return self.directional_motion_blur(image, p.size, p.angle, p.strength)
        elif p.motion_type == "radial":
            return self.radial_motion_blur(image, p.strength)
        elif p.motion_type == "rotational":
            return self.rotational_motion_blur(image, p.strength)
        elif p.motion_type == "zoom":
            return self.zoom_motion_blur(image, p.strength)
        else:
            return self.directional_motion_blur(image, p.size, p.angle, p.strength)

    def artistic_showcase(self, image: np.ndarray, save_path: Optional[str] = None) -> None:
        """
        ğŸ­ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å±•ç¤ºï¼šå±•ç°æ—¶é—´çš„å¤šç§è¯—æ„è¡¨è¾¾

        å¦‚åŒæ—¶é—´è‰ºæœ¯é¦†çš„ä½œå“å±•è§ˆï¼Œå±•ç¤ºè¿åŠ¨çš„æ— é™å¯èƒ½
        """
        print("ğŸ¨ å¼€å§‹åˆ›ä½œè¿åŠ¨æ¨¡ç³Šè‰ºæœ¯ä½œå“...")

        # ğŸ¨ åˆ›å»ºä¸åŒé£æ ¼çš„è¿åŠ¨ä½œå“
        effects = {
            "ğŸ“· é™æ­¢çš„ç¬é—´": image,
            "ğŸƒâ€â™‚ï¸ çº¿æ€§è¿åŠ¨": self.directional_motion_blur(image, 25, 45, 0.8),
            "ğŸŒªï¸ é£æš´æ—‹è½¬": self.directional_motion_blur(image, 30, 90, 1.0),
            "ğŸŒ€ å¾„å‘æ‰©æ•£": self.radial_motion_blur(image, 0.6),
            "ğŸ’« æ—‹è½¬éŸµå¾‹": self.rotational_motion_blur(image, 0.7),
            "ğŸ¯ ç¼©æ”¾éš§é“": self.zoom_motion_blur(image, 0.5),
            "âš¡ é«˜é€Ÿè¿åŠ¨": self.directional_motion_blur(image, 40, 0, 0.9),
            "ğŸŒŠ æ—¶é—´æ¶Ÿæ¼ª": self.radial_motion_blur(image, 0.8)
        }

        # ğŸ–¼ï¸ åˆ›é€ æ—¶é—´è‰ºæœ¯é¦†
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('ğŸŒŠ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯é¦†ï¼šæ—¶é—´çš„è¯—æ„è¡¨è¾¾', fontsize=16, fontweight='bold')

        for i, (title, effect_image) in enumerate(effects.items()):
            row, col = i // 4, i % 4
            axes[row, col].imshow(cv2.cvtColor(effect_image, cv2.COLOR_BGR2RGB))
            axes[row, col].set_title(title, fontsize=11)
            axes[row, col].axis('off')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å±•ç¤ºå·²ä¿å­˜è‡³: {save_path}")

        plt.show()

    def motion_analysis(self, image: np.ndarray) -> None:
        """
        ğŸ” è¿åŠ¨æ¨¡ç³Šæ•ˆæœåˆ†æï¼šå±•ç¤ºä¸åŒå‚æ•°çš„å½±å“
        """
        print("ğŸ” åˆ†æè¿åŠ¨å‚æ•°å¯¹æ¨¡ç³Šæ•ˆæœçš„å½±å“...")

        # æµ‹è¯•ä¸åŒçš„è¿åŠ¨æ–¹å‘
        angles = [0, 30, 60, 90]
        angle_results = []

        for angle in angles:
            result = self.directional_motion_blur(image, 20, angle, 0.8)
            angle_results.append((f"è§’åº¦: {angle}Â°", result))

        # æµ‹è¯•ä¸åŒçš„è¿åŠ¨å¼ºåº¦
        strengths = [0.3, 0.6, 0.9, 1.2]
        strength_results = []

        for strength in strengths:
            result = self.directional_motion_blur(image, 25, 45, strength)
            strength_results.append((f"å¼ºåº¦: {strength}", result))

        # å¯è§†åŒ–å¯¹æ¯”
        fig, axes = plt.subplots(2, 4, figsize=(16, 8))
        fig.suptitle('ğŸ” è¿åŠ¨å‚æ•°å½±å“åˆ†æ', fontsize=14, fontweight='bold')

        # æ˜¾ç¤ºè§’åº¦å½±å“
        for i, (title, img) in enumerate(angle_results):
            axes[0, i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            axes[0, i].set_title(title, fontsize=10)
            axes[0, i].axis('off')

        # æ˜¾ç¤ºå¼ºåº¦å½±å“
        for i, (title, img) in enumerate(strength_results):
            axes[1, i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            axes[1, i].set_title(title, fontsize=10)
            axes[1, i].axis('off')

        plt.tight_layout()
        plt.show()

    def motion_type_comparison(self, image: np.ndarray) -> None:
        """
        ğŸª è¿åŠ¨ç±»å‹å¯¹æ¯”ï¼šä¸åŒè¿åŠ¨æ¨¡å¼çš„è‰ºæœ¯è¡¨è¾¾
        """
        print("ğŸª å±•ç¤ºä¸åŒçš„è¿åŠ¨æ¨¡ç³Šç±»å‹...")

        motion_types = {
            "ğŸ“· åŸå›¾": image,
            "ğŸƒâ€â™‚ï¸ çº¿æ€§è¿åŠ¨": self.directional_motion_blur(image, 25, 30, 0.8),
            "ğŸŒ€ å¾„å‘è¿åŠ¨": self.radial_motion_blur(image, 0.6),
            "ğŸŒªï¸ æ—‹è½¬è¿åŠ¨": self.rotational_motion_blur(image, 0.7),
            "ğŸ¯ ç¼©æ”¾è¿åŠ¨": self.zoom_motion_blur(image, 0.6),
            "âš¡ å¿«é€Ÿçº¿æ€§": self.directional_motion_blur(image, 35, 0, 1.0),
            "ğŸ’« å¿«é€Ÿæ—‹è½¬": self.rotational_motion_blur(image, 0.9),
            "ğŸŒŠ å¼ºå¾„å‘": self.radial_motion_blur(image, 0.8)
        }

        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('ğŸª è¿åŠ¨ç±»å‹å¯¹æ¯”ï¼šæ—¶é—´çš„å¤šç§éŸµå¾‹', fontsize=16, fontweight='bold')

        for i, (title, motion_image) in enumerate(motion_types.items()):
            row, col = i // 4, i % 4
            axes[row, col].imshow(cv2.cvtColor(motion_image, cv2.COLOR_BGR2RGB))
            axes[row, col].set_title(title, fontsize=11)
            axes[row, col].axis('off')

        plt.tight_layout()
        plt.show()

    def interactive_motion_blur(self, image: np.ndarray) -> None:
        """
        ğŸ® äº¤äº’å¼è¿åŠ¨æ¨¡ç³Šï¼šå®æ—¶è°ƒæ•´å‚æ•°ä½“éªŒæ—¶é—´é­”æ³•

        Args:
            image: è¾“å…¥å›¾åƒ
        """
        try:
            from matplotlib.widgets import Slider, RadioButtons
        except ImportError:
            print("âŒ éœ€è¦matplotlib.widgetsæ¨¡å—è¿›è¡Œäº¤äº’å¼æ¼”ç¤º")
            return

        fig = plt.figure(figsize=(16, 10))

        # åˆ›å»ºå­å›¾å¸ƒå±€
        ax_original = plt.subplot2grid((4, 4), (0, 0), rowspan=2, colspan=2)
        ax_result = plt.subplot2grid((4, 4), (0, 2), rowspan=2, colspan=2)
        ax_motion_type = plt.subplot2grid((4, 4), (2, 0), rowspan=1, colspan=1)

        # æ˜¾ç¤ºåŸå›¾
        ax_original.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        ax_original.set_title('ğŸ“· åŸå§‹å›¾åƒ', fontsize=12)
        ax_original.axis('off')

        # åˆå§‹æ•ˆæœ
        initial_result = self.directional_motion_blur(image, 15, 45, 0.8)
        im_result = ax_result.imshow(cv2.cvtColor(initial_result, cv2.COLOR_BGR2RGB))
        ax_result.set_title('ğŸŒŠ è¿åŠ¨æ¨¡ç³Šæ•ˆæœ', fontsize=12)
        ax_result.axis('off')

        # è¿åŠ¨ç±»å‹é€‰æ‹©
        motion_types = ['çº¿æ€§', 'å¾„å‘', 'æ—‹è½¬', 'ç¼©æ”¾']
        radio = RadioButtons(ax_motion_type, motion_types, active=0)
        ax_motion_type.set_title('ğŸ¨ è¿åŠ¨ç±»å‹')

        # åˆ›å»ºæ»‘å—
        ax_size = plt.axes([0.15, 0.25, 0.25, 0.03])
        ax_angle = plt.axes([0.55, 0.25, 0.25, 0.03])
        ax_strength = plt.axes([0.15, 0.2, 0.25, 0.03])
        ax_center_x = plt.axes([0.55, 0.2, 0.25, 0.03])
        ax_center_y = plt.axes([0.15, 0.15, 0.25, 0.03])

        slider_size = Slider(ax_size, 'æ ¸å¤§å°', 5, 50, valinit=15, valfmt='%d')
        slider_angle = Slider(ax_angle, 'è§’åº¦', 0, 360, valinit=45)
        slider_strength = Slider(ax_strength, 'å¼ºåº¦', 0.1, 2.0, valinit=0.8)
        slider_center_x = Slider(ax_center_x, 'ä¸­å¿ƒX', 0, image.shape[1], valinit=image.shape[1]//2, valfmt='%d')
        slider_center_y = Slider(ax_center_y, 'ä¸­å¿ƒY', 0, image.shape[0], valinit=image.shape[0]//2, valfmt='%d')

        def update(_):
            """æ›´æ–°è¿åŠ¨æ¨¡ç³Šæ•ˆæœ"""
            motion_type = radio.value_selected
            size = int(slider_size.val)
            angle = slider_angle.val
            strength = slider_strength.val
            center_x = int(slider_center_x.val)
            center_y = int(slider_center_y.val)

            if motion_type == 'çº¿æ€§':
                result = self.directional_motion_blur(image, size, angle, strength)
            elif motion_type == 'å¾„å‘':
                result = self.radial_motion_blur(image, strength, (center_x, center_y))
            elif motion_type == 'æ—‹è½¬':
                result = self.rotational_motion_blur(image, strength, (center_x, center_y))
            elif motion_type == 'ç¼©æ”¾':
                result = self.zoom_motion_blur(image, strength, (center_x, center_y))

            im_result.set_data(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
            ax_result.set_title(f'ğŸŒŠ {motion_type}è¿åŠ¨æ¨¡ç³Š')
            fig.canvas.draw()

        # ç»‘å®šäº‹ä»¶
        slider_size.on_changed(update)
        slider_angle.on_changed(update)
        slider_strength.on_changed(update)
        slider_center_x.on_changed(update)
        slider_center_y.on_changed(update)
        radio.on_clicked(update)

        plt.tight_layout()
        plt.show()

    def performance_test(self, image_sizes: List[Tuple[int, int]] = None) -> Dict[str, float]:
        """
        âš¡ æ€§èƒ½æµ‹è¯•ï¼šè¯„ä¼°ä¸åŒè¿åŠ¨æ¨¡ç³Šæ–¹æ³•çš„å¤„ç†é€Ÿåº¦

        Args:
            image_sizes: æµ‹è¯•çš„å›¾åƒå°ºå¯¸åˆ—è¡¨

        Returns:
            æ€§èƒ½æµ‹è¯•ç»“æœå­—å…¸
        """
        if image_sizes is None:
            image_sizes = [(256, 256), (512, 512), (1024, 1024)]

        results = {}

        print("ğŸš€ å¼€å§‹è¿åŠ¨æ¨¡ç³Šæ€§èƒ½æµ‹è¯•...")
        print("=" * 60)

        for width, height in image_sizes:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)

            # æµ‹è¯•ä¸åŒæ–¹æ³•
            methods = {
                'çº¿æ€§è¿åŠ¨æ¨¡ç³Š': lambda img: self.directional_motion_blur(img, 25, 45, 0.8),
                'å¾„å‘è¿åŠ¨æ¨¡ç³Š': lambda img: self.radial_motion_blur(img, 0.6),
                'æ—‹è½¬è¿åŠ¨æ¨¡ç³Š': lambda img: self.rotational_motion_blur(img, 0.7),
                'ç¼©æ”¾è¿åŠ¨æ¨¡ç³Š': lambda img: self.zoom_motion_blur(img, 0.5)
            }

            print(f"ğŸ“Š å›¾åƒå°ºå¯¸: {width}x{height}")

            for method_name, method_func in methods.items():
                start_time = time.time()
                _ = method_func(test_image)
                processing_time = time.time() - start_time

                key = f"{method_name}_{width}x{height}"
                results[key] = processing_time

                print(f"  ğŸŒŠ {method_name}: {processing_time:.3f}ç§’")

            print("-" * 40)

        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
        return results

def create_motion_blur_demo():
    """ğŸ¯ åˆ›å»ºè¿åŠ¨æ¨¡ç³Šæ¼”ç¤ºç¨‹åº"""

    def process_image_interactive():
        """äº¤äº’å¼å›¾åƒå¤„ç†"""
        while True:
            print("\n" + "="*60)
            print("ğŸŒŠ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶ - äº¤äº’å¼æ¼”ç¤º")
            print("="*60)

            # è·å–å›¾åƒè·¯å¾„
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„ (æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
            if image_path.lower() == 'q':
                break

            if not os.path.exists(image_path):
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
                continue

            # åŠ è½½å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
                continue

            print(f"âœ… æˆåŠŸåŠ è½½å›¾åƒ: {image.shape}")

            # åˆ›å»ºè¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶
            artist = MotionBlurArtist()

            print("\nğŸ¨ è¯·é€‰æ‹©è¿åŠ¨æ¨¡ç³Šç±»å‹:")
            print("1. ğŸƒâ€â™‚ï¸ çº¿æ€§è¿åŠ¨æ¨¡ç³Š")
            print("2. ğŸŒ€ å¾„å‘è¿åŠ¨æ¨¡ç³Š")
            print("3. ğŸŒªï¸ æ—‹è½¬è¿åŠ¨æ¨¡ç³Š")
            print("4. ğŸ¯ ç¼©æ”¾è¿åŠ¨æ¨¡ç³Š")
            print("5. ğŸ¨ è‰ºæœ¯å±•ç¤º")
            print("6. ğŸª ç±»å‹å¯¹æ¯”")
            print("7. ğŸ” å‚æ•°åˆ†æ")
            print("8. ğŸ® äº¤äº’å¼è°ƒèŠ‚")

            choice = input("è¯·é€‰æ‹© (1-8): ").strip()

            try:
                if choice == '1':
                    size = int(input("ğŸƒâ€â™‚ï¸ æ ¸å¤§å° [5-50, é»˜è®¤25]: ") or "25")
                    angle = float(input("ğŸƒâ€â™‚ï¸ è¿åŠ¨è§’åº¦ [0-360, é»˜è®¤45]: ") or "45")
                    strength = float(input("ğŸƒâ€â™‚ï¸ è¿åŠ¨å¼ºåº¦ [0.1-2.0, é»˜è®¤0.8]: ") or "0.8")
                    result = artist.directional_motion_blur(image, size, angle, strength)
                elif choice == '2':
                    strength = float(input("ğŸŒ€ æ‰©æ•£å¼ºåº¦ [0.1-1.0, é»˜è®¤0.6]: ") or "0.6")
                    result = artist.radial_motion_blur(image, strength)
                elif choice == '3':
                    strength = float(input("ğŸŒªï¸ æ—‹è½¬å¼ºåº¦ [0.1-1.0, é»˜è®¤0.7]: ") or "0.7")
                    result = artist.rotational_motion_blur(image, strength)
                elif choice == '4':
                    strength = float(input("ğŸ¯ ç¼©æ”¾å¼ºåº¦ [0.1-1.0, é»˜è®¤0.5]: ") or "0.5")
                    result = artist.zoom_motion_blur(image, strength)
                elif choice == '5':
                    artist.artistic_showcase(image)
                    continue
                elif choice == '6':
                    artist.motion_type_comparison(image)
                    continue
                elif choice == '7':
                    artist.motion_analysis(image)
                    continue
                elif choice == '8':
                    artist.interactive_motion_blur(image)
                    continue
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
                    continue

                # æ˜¾ç¤ºç»“æœ
                comparison = np.hstack([image, result])
                cv2.imshow("Motion Blur (Original | Blurred)", comparison)
                cv2.waitKey(0)
                cv2.destroyAllWindows()

                # è¯¢é—®æ˜¯å¦ä¿å­˜
                save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜ç»“æœ? (y/n): ").strip().lower()
                if save_choice == 'y':
                    output_path = input("ğŸ“ è¾“å…¥ä¿å­˜è·¯å¾„ (é»˜è®¤: motion_blur_result.jpg): ").strip() or "motion_blur_result.jpg"
                    cv2.imwrite(output_path, result)
                    print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {output_path}")

            except ValueError:
                print("âŒ å‚æ•°æ ¼å¼é”™è¯¯")
            except Exception as e:
                print(f"âŒ å¤„ç†å‡ºé”™: {e}")

    def batch_process_demo():
        """æ‰¹é‡å¤„ç†æ¼”ç¤º"""
        print("\n" + "="*60)
        print("ğŸš€ æ‰¹é‡è¿åŠ¨æ¨¡ç³Šå¤„ç†æ¼”ç¤º")
        print("="*60)

        input_dir = input("ğŸ“ è¾“å…¥å›¾åƒç›®å½•è·¯å¾„: ").strip()
        if not os.path.exists(input_dir):
            print("âŒ ç›®å½•ä¸å­˜åœ¨")
            return

        output_dir = input("ğŸ“ è¾“å‡ºç›®å½•è·¯å¾„: ").strip() or "motion_blur_results"
        os.makedirs(output_dir, exist_ok=True)

        # é€‰æ‹©è¿åŠ¨ç±»å‹
        print("\nğŸ¨ é€‰æ‹©è¿åŠ¨æ¨¡ç³Šç±»å‹:")
        print("1. çº¿æ€§è¿åŠ¨")
        print("2. å¾„å‘è¿åŠ¨")
        print("3. æ—‹è½¬è¿åŠ¨")
        print("4. ç¼©æ”¾è¿åŠ¨")

        motion_choice = input("è¯·é€‰æ‹© (1-4): ").strip()
        motion_map = {
            '1': ('linear', 'çº¿æ€§è¿åŠ¨'),
            '2': ('radial', 'å¾„å‘è¿åŠ¨'),
            '3': ('rotational', 'æ—‹è½¬è¿åŠ¨'),
            '4': ('zoom', 'ç¼©æ”¾è¿åŠ¨')
        }

        if motion_choice not in motion_map:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return

        motion_type, motion_name = motion_map[motion_choice]

        # è·å–å›¾åƒæ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = [f for f in os.listdir(input_dir)
                      if Path(f).suffix.lower() in image_extensions]

        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return

        print(f"ğŸ“¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")

        # åˆ›å»ºè¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶
        artist = MotionBlurArtist()

        # æ‰¹é‡å¤„ç†
        for i, filename in enumerate(image_files):
            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(output_dir, f"motion_blur_{filename}")

            print(f"ğŸ¨ å¤„ç† ({i+1}/{len(image_files)}): {filename}")

            image = cv2.imread(input_path)
            if image is not None:
                if motion_type == 'linear':
                    result = artist.directional_motion_blur(image, 25, 45, 0.8)
                elif motion_type == 'radial':
                    result = artist.radial_motion_blur(image, 0.6)
                elif motion_type == 'rotational':
                    result = artist.rotational_motion_blur(image, 0.7)
                elif motion_type == 'zoom':
                    result = artist.zoom_motion_blur(image, 0.5)

                cv2.imwrite(output_path, result)
                print(f"âœ… å·²ä¿å­˜: {output_path}")
            else:
                print(f"âŒ æ— æ³•è¯»å–: {filename}")

        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")

    # ä¸»èœå•
    while True:
        print("\n" + "="*70)
        print("ğŸŒŠ è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶ - æ—¶é—´çš„è¯—æ„è¡¨è¾¾")
        print("="*70)
        print("1. ğŸ“· äº¤äº’å¼å•å›¾å¤„ç†")
        print("2. ğŸš€ æ‰¹é‡å›¾åƒå¤„ç†")
        print("3. ğŸ¨ è‰ºæœ¯æ•ˆæœå±•ç¤º")
        print("4. ğŸª è¿åŠ¨ç±»å‹å¯¹æ¯”")
        print("5. ğŸ® äº¤äº’å¼å‚æ•°è°ƒèŠ‚")
        print("6. ğŸ“Š æ€§èƒ½æµ‹è¯•")
        print("7. ğŸ” å‚æ•°å½±å“åˆ†æ")
        print("0. ğŸ‘‹ é€€å‡ºç¨‹åº")
        print("="*70)

        choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (0-7): ").strip()

        if choice == '0':
            print("ğŸ‘‹ æ„Ÿè°¢ä½“éªŒè¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶ï¼")
            print("æ„¿ä½ çš„ä¸–ç•Œå¦‚æ—¶é—´èˆ¬å……æ»¡æµåŠ¨çš„ç¾æ„Ÿï¼ âœ¨")
            break
        elif choice == '1':
            process_image_interactive()
        elif choice == '2':
            batch_process_demo()
        elif choice == '3':
            image_path = input("ğŸ“· è¯·è¾“å…¥æµ‹è¯•å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = MotionBlurArtist()
                    artist.artistic_showcase(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '4':
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = MotionBlurArtist()
                    artist.motion_type_comparison(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '5':
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = MotionBlurArtist()
                    artist.interactive_motion_blur(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '6':
            artist = MotionBlurArtist()
            artist.performance_test()
        elif choice == '7':
            image_path = input("ğŸ“· è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                image = cv2.imread(image_path)
                if image is not None:
                    artist = MotionBlurArtist()
                    artist.motion_analysis(image)
                else:
                    print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def main():
    """ğŸŒŸ ä¸»å‡½æ•°ï¼šå±•ç¤ºè¿åŠ¨æ¨¡ç³Šçš„æ—¶é—´é­”æ³•"""
    parser = argparse.ArgumentParser(description="ğŸŒŠ è¿åŠ¨æ¨¡ç³Š - æ—¶é—´çš„è¯—æ„è¡¨è¾¾")
    parser.add_argument("--input", "-i", type=str, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", type=str, help="è¾“å‡ºå›¾åƒè·¯å¾„")
    parser.add_argument("--type", "-t", type=str, default="linear",
                       choices=["linear", "radial", "rotational", "zoom"],
                       help="è¿åŠ¨ç±»å‹")
    parser.add_argument("--size", "-s", type=int, default=25, help="æ ¸å¤§å° (5-50)")
    parser.add_argument("--angle", "-a", type=float, default=45.0, help="è¿åŠ¨è§’åº¦ (0-360)")
    parser.add_argument("--strength", type=float, default=0.8, help="è¿åŠ¨å¼ºåº¦ (0.1-2.0)")
    parser.add_argument("--center-x", type=int, default=-1, help="ä¸­å¿ƒç‚¹Xåæ ‡")
    parser.add_argument("--center-y", type=int, default=-1, help="ä¸­å¿ƒç‚¹Yåæ ‡")
    parser.add_argument("--demo", action="store_true", help="å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")
    parser.add_argument("--showcase", action="store_true", help="æ˜¾ç¤ºè‰ºæœ¯å±•ç¤º")
    parser.add_argument("--comparison", action="store_true", help="æ˜¾ç¤ºç±»å‹å¯¹æ¯”")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼å‚æ•°è°ƒèŠ‚")
    parser.add_argument("--analysis", action="store_true", help="å‚æ•°å½±å“åˆ†æ")
    parser.add_argument("--performance", action="store_true", help="è¿è¡Œæ€§èƒ½æµ‹è¯•")

    args = parser.parse_args()

    if args.demo:
        create_motion_blur_demo()
        return

    if not args.input:
        print("ğŸš« è¯·æä¾›è¾“å…¥å›¾åƒè·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --demo å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")
        print("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹: python motion_blur_effect.py -i image.jpg -o result.jpg")
        print("ğŸ’¡ æ¼”ç¤ºæ¨¡å¼: python motion_blur_effect.py --demo")
        return

    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return

    # åŠ è½½å›¾åƒ
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {args.input}")
        return

    print(f"âœ… æˆåŠŸåŠ è½½å›¾åƒ: {image.shape}")

    # åˆ›å»ºè¿åŠ¨æ¨¡ç³Šè‰ºæœ¯å®¶
    artist = MotionBlurArtist()

    if args.performance:
        # æ€§èƒ½æµ‹è¯•
        artist.performance_test()
        return

    if args.showcase:
        # è‰ºæœ¯å±•ç¤º
        save_path = args.output.replace('.jpg', '_showcase.png') if args.output else None
        artist.artistic_showcase(image, save_path)
        return

    if args.comparison:
        # ç±»å‹å¯¹æ¯”
        artist.motion_type_comparison(image)
        return

    if args.interactive:
        # äº¤äº’å¼è°ƒèŠ‚
        artist.interactive_motion_blur(image)
        return

    if args.analysis:
        # å‚æ•°åˆ†æ
        artist.motion_analysis(image)
        return

    # åº”ç”¨æŒ‡å®šçš„è¿åŠ¨æ¨¡ç³Š
    print(f"ğŸ¨ åº”ç”¨{args.type}è¿åŠ¨æ¨¡ç³Š...")

    center = None
    if args.center_x >= 0 and args.center_y >= 0:
        center = (args.center_x, args.center_y)

    if args.type == "linear":
        result = artist.directional_motion_blur(image, args.size, args.angle, args.strength)
    elif args.type == "radial":
        result = artist.radial_motion_blur(image, args.strength, center)
    elif args.type == "rotational":
        result = artist.rotational_motion_blur(image, args.strength, center)
    elif args.type == "zoom":
        result = artist.zoom_motion_blur(image, args.strength, center)

    if args.output:
        cv2.imwrite(args.output, result)
        print(f"âœ… è¿åŠ¨æ¨¡ç³Šè‰ºæœ¯ä½œå“å·²ä¿å­˜è‡³: {args.output}")
    else:
        # æ˜¾ç¤ºå¯¹æ¯”
        comparison = np.hstack([image, result])
        cv2.imshow("Motion Blur (Original | Blurred)", comparison)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()