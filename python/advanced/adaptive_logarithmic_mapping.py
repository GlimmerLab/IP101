#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŸ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„ç®—æ³•ï¼šæ•°å­—ä¸–ç•Œçš„æ™ºæ…§çœ¼é•œ
=====================================

ğŸ¨ è¿™æ˜¯ä¸€ä¸ªå°†æ•°å­¦ä¹‹ç¾ä¸è§†è§‰è‰ºæœ¯å®Œç¾èåˆçš„ç®—æ³•å®ç°
æ¯ä¸€è¡Œä»£ç éƒ½æ‰¿è½½ç€å¯¹å…‰å½±å¹³è¡¡çš„æ·±åº¦ç†è§£

ä½œè€…: GlimmerLab è§†è§‰ç®—æ³•å®éªŒå®¤
é¡¹ç›®: IP101 - å›¾åƒå¤„ç†ç®—æ³•é›†
æè¿°: è‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„è¯—æ„å®ç°
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import argparse
import os
import time
from typing import Tuple, Optional, Dict, Any, Union
from dataclasses import dataclass
from matplotlib.patches import Rectangle
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œç¾è§‚çš„æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

@dataclass
class AdaptiveLogParams:
    """
    ğŸŒŸ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„è‰ºæœ¯å‚æ•°é›†åˆ

    æ¯ä¸ªå‚æ•°éƒ½å¦‚éŸ³ç¬¦èˆ¬ç²¾å¿ƒè°ƒæ ¡ï¼Œå…±åŒè°±å†™è§†è§‰çš„äº¤å“ä¹
    """
    bias: float = 0.85                 # åç½®å‚æ•°ï¼šç”Ÿæ´»çš„åŸºè°ƒï¼Œå†³å®šæ•´ä½“äº®åº¦å€¾å‘
    max_scale: float = 100.0           # æœ€å¤§ç¼©æ”¾å› å­ï¼šäººç”Ÿçš„æ ¼å±€ï¼Œæ§åˆ¶å¯¹æ¯”åº¦å¹…åº¦
    local_adaptation: bool = False     # å±€éƒ¨è‡ªé€‚åº”ï¼šå› åœ°åˆ¶å®œçš„æ™ºæ…§å¼€å…³
    window_ratio: float = 0.125        # çª—å£æ¯”ä¾‹ï¼šè§‚å¯Ÿä¸–ç•Œçš„è§†é‡å¤§å°
    tone_curve_strength: float = 0.3   # è‰²è°ƒæ›²çº¿å¼ºåº¦ï¼šSå‹æ›²çº¿çš„ä¼˜é›…ç¨‹åº¦

    def __post_init__(self):
        """å‚æ•°éªŒè¯ï¼šç¡®ä¿æ¯ä¸ªå‚æ•°éƒ½åœ¨åˆç†èŒƒå›´å†…"""
        assert 0.0 <= self.bias <= 2.0, "ğŸš« åç½®å‚æ•°åº”åœ¨[0, 2]èŒƒå›´å†…"
        assert 1.0 <= self.max_scale <= 500.0, "ğŸš« æœ€å¤§ç¼©æ”¾å› å­åº”åœ¨[1, 500]èŒƒå›´å†…"
        assert 0.01 <= self.window_ratio <= 0.5, "ğŸš« çª—å£æ¯”ä¾‹åº”åœ¨[0.01, 0.5]èŒƒå›´å†…"
        assert 0.0 <= self.tone_curve_strength <= 1.0, "ğŸš« è‰²è°ƒæ›²çº¿å¼ºåº¦åº”åœ¨[0, 1]èŒƒå›´å†…"

class AdaptiveLogArtist:
    """
    ğŸ¨ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„è‰ºæœ¯å®¶

    å¦‚åŒç»éªŒä¸°å¯Œçš„è°ƒè‰²å¸ˆï¼Œæ ¹æ®æ¯å¼ ç”»å¸ƒçš„ç‰¹ç‚¹ç²¾å¿ƒè°ƒåˆ¶è‰²å½©
    åœ¨æ•°å­¦çš„ç²¾ç¡®ä¸è‰ºæœ¯çš„æ„Ÿæ€§ä¹‹é—´å¯»æ‰¾å®Œç¾çš„å¹³è¡¡ç‚¹
    """

    def __init__(self, params: Optional[AdaptiveLogParams] = None):
        """
        ğŸŒŸ åˆå§‹åŒ–æˆ‘ä»¬çš„è§†è§‰è°ƒè‰²å¸ˆ

        Args:
            params: è‡ªé€‚åº”å¯¹æ•°æ˜ å°„å‚æ•°ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤çš„è‰ºæœ¯é…ç½®
        """
        self.params = params or AdaptiveLogParams()
        print("ğŸ¨ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„è‰ºæœ¯å®¶å·²å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹åˆ›ä½œæ•°å­¦ä¸ç¾å­¦çš„äº¤å“è¯—ï¼")

    def basic_log_mapping(self, image: np.ndarray) -> np.ndarray:
        """
        ğŸŒ… åŸºç¡€å¯¹æ•°æ˜ å°„ï¼šå‘ç°å¯¹æ•°ç¾å­¦çš„ç¬¬ä¸€æ­¥

        å¦‚åŒå­¦ä¹ éŸ³ä¹çš„ç¬¬ä¸€ä¸ªéŸ³ç¬¦ï¼Œç®€å•å´è•´å«æ·±æ„
        è¿™æ˜¯ç†è§£å¯¹æ•°å˜æ¢æœ€æœ´ç´ è€Œçº¯çœŸçš„æ–¹å¼

        Args:
            image: è¾“å…¥å›¾åƒï¼Œæ”¯æŒç°åº¦å’Œå½©è‰²

        Returns:
            å¯¹æ•°æ˜ å°„åçš„å›¾åƒï¼Œå±•ç°åŸºç¡€çš„åŠ¨æ€èŒƒå›´å‹ç¼©ä¹‹ç¾

        Raises:
            ValueError: å½“è¾“å…¥å›¾åƒä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®æ—¶
        """
        if image is None or image.size == 0:
            raise ValueError("ğŸš« è¾“å…¥å›¾åƒä¸ºç©ºï¼Œè¯·æä¾›æœ‰æ•ˆçš„å›¾åƒæ•°æ®")

        # ğŸŒŸ è½¬æ¢ä¸ºæµ®ç‚¹å‹ï¼Œå¼€å¯ç²¾ç¡®è®¡ç®—çš„å¤§é—¨
        # æµ®ç‚¹è¿ç®—å¦‚åŒè‰ºæœ¯åˆ›ä½œï¼Œéœ€è¦ç²¾ç¡®çš„æ§åˆ¶
        float_img = image.astype(np.float32)

        # ğŸ“Š æ‰¾åˆ°å›¾åƒçš„å³°å€¼ï¼šäº†è§£ä¸–ç•Œçš„ä¸Šé™
        # æ¯å¼ å›¾åƒéƒ½æœ‰å…¶ç‹¬ç‰¹çš„åŠ¨æ€èŒƒå›´ç‰¹å¾
        max_val = np.max(float_img)

        if max_val <= 0:
            print("âš ï¸ æ£€æµ‹åˆ°å›¾åƒæœ€å¤§å€¼ä¸º0ï¼Œè¿”å›åŸå›¾")
            return image

        # âœ¨ åº”ç”¨å¯¹æ•°å˜æ¢ï¼šæ•°å­¦çš„é­”æ³•æ—¶åˆ»
        # å¯¹æ•°å‡½æ•°çš„éçº¿æ€§ç‰¹æ€§æ¨¡æ‹Ÿäººçœ¼çš„è§†è§‰å“åº”
        log_img = np.log(float_img + 1.0)  # åŠ 1é¿å…log(0)çš„æ•°å­¦å›°æ‰°

        # ğŸ¨ å½’ä¸€åŒ–åˆ°å¯è§èŒƒå›´ï¼šè®©ç¾å›å½’äººçœ¼çš„ä¸–ç•Œ
        # å°†æ— é™çš„æ•°å­¦ç©ºé—´æ˜ å°„åˆ°æœ‰é™çš„æ˜¾ç¤ºç©ºé—´
        normalized = log_img * 255.0 / np.log(max_val + 1.0)

        return np.clip(normalized, 0, 255).astype(np.uint8)

    def adaptive_log_mapping(self, image: np.ndarray,
                           params: Optional[AdaptiveLogParams] = None) -> np.ndarray:
        """
        ğŸŒˆ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„ï¼šæ™ºæ…§é€‰æ‹©çš„æ•°å­¦è¯—ç¯‡

        å¦‚åŒç»éªŒä¸°å¯Œçš„è°ƒè‰²å¸ˆï¼Œæ ¹æ®æ¯å¼ ç”»å¸ƒçš„ç‰¹ç‚¹è°ƒæ•´è‰²å½©
        è¿™æ˜¯å¯¹æ•°æ˜ å°„çš„è¿›é˜¶å½¢æ€ï¼Œä½“ç°å› ææ–½æ•™çš„ç®—æ³•æ™ºæ…§

        Args:
            image: è¾“å…¥å›¾åƒï¼Œæ”¯æŒç°åº¦å’Œå½©è‰²æ ¼å¼
            params: æ˜ å°„å‚æ•°ï¼Œå¦‚ä¸æä¾›åˆ™ä½¿ç”¨å®ä¾‹é»˜è®¤å‚æ•°

        Returns:
            è‡ªé€‚åº”å¯¹æ•°æ˜ å°„åçš„å›¾åƒï¼Œå±•ç°ä¸ªæ€§åŒ–çš„åŠ¨æ€èŒƒå›´è°ƒæ•´

        Raises:
            ValueError: å½“è¾“å…¥å›¾åƒæ ¼å¼ä¸æ”¯æŒæ—¶
        """
        if image is None or image.size == 0:
            raise ValueError("ğŸš« è¾“å…¥å›¾åƒä¸ºç©º")

        p = params or self.params

        # ğŸ¯ è½¬æ¢ä¸ºæµ®ç‚¹å‹ï¼šè¿›å…¥ç²¾ç¡®çš„æ•°å­¦æ®¿å ‚
        float_img = image.astype(np.float32)

        if len(image.shape) == 2:
            # ğŸŒ™ ç°åº¦å›¾åƒï¼šå•è‰²ä¸–ç•Œçš„å¯¹æ•°ä¹‹ç¾
            return self._process_grayscale(float_img, p)
        elif len(image.shape) == 3:
            # ğŸŒˆ å½©è‰²å›¾åƒï¼šå¤šå½©ä¸–ç•Œçš„å’Œè°ç»Ÿä¸€
            return self._process_color(float_img, p)
        else:
            raise ValueError(f"ğŸš« ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼ï¼Œç»´åº¦: {len(image.shape)}")

    def _process_grayscale(self, float_img: np.ndarray,
                          params: AdaptiveLogParams) -> np.ndarray:
        """
        ğŸŒ™ å¤„ç†ç°åº¦å›¾åƒçš„ç§æœ‰æ–¹æ³•

        ç°åº¦ä¸–ç•Œè™½ç„¶æ²¡æœ‰è‰²å½©çš„ç»šçƒ‚ï¼Œå´æœ‰ç€çº¯ç²¹çš„æ˜æš—ä¹‹ç¾

        Args:
            float_img: æµ®ç‚¹å‹ç°åº¦å›¾åƒ
            params: è‡ªé€‚åº”å‚æ•°

        Returns:
            å¤„ç†åçš„ç°åº¦å›¾åƒ
        """
        # ğŸ“Š è®¡ç®—å›¾åƒç»Ÿè®¡ï¼šäº†è§£å›¾åƒçš„æ€§æ ¼ç‰¹å¾
        max_val = np.max(float_img)
        mean_val = np.mean(float_img)

        if max_val <= 0:
            return np.zeros_like(float_img, dtype=np.uint8)

        # ğŸ§® è®¡ç®—è‡ªé€‚åº”ç¼©æ”¾å› å­ï¼šå› ææ–½æ•™çš„æ™ºæ…§
        # æ ¹æ®å›¾åƒçš„åŠ¨æ€èŒƒå›´è‡ªåŠ¨è°ƒæ•´æ˜ å°„å¼ºåº¦
        scale = params.max_scale / np.log10(max_val + 1.0)

        # ğŸ¨ æ™ºèƒ½åç½®è°ƒæ•´ï¼šæ ¹æ®å›¾åƒå¹³å‡äº®åº¦å¾®è°ƒåŸºè°ƒ
        adaptive_bias = params.bias + 0.1 * (128 - mean_val) / 128

        # âœ¨ åº”ç”¨å¯¹æ•°æ˜ å°„ï¼šæ•°å­¦ä¸è‰ºæœ¯çš„é‚‚é€…
        log_img = np.log(float_img + 1.0) * scale + adaptive_bias

        return np.clip(log_img, 0, 255).astype(np.uint8)

    def _process_color(self, float_img: np.ndarray,
                      params: AdaptiveLogParams) -> np.ndarray:
        """
        ğŸŒˆ å¤„ç†å½©è‰²å›¾åƒçš„ç§æœ‰æ–¹æ³•

        å½©è‰²å›¾åƒå¦‚åŒäº¤å“ä¹ï¼Œéœ€è¦åè°ƒå¤„ç†æ¯ä¸ªé¢œè‰²é€šé“

        Args:
            float_img: æµ®ç‚¹å‹å½©è‰²å›¾åƒ
            params: è‡ªé€‚åº”å‚æ•°

        Returns:
            å¤„ç†åçš„å½©è‰²å›¾åƒ
        """
        if params.local_adaptation:
            # ğŸ­ å±€éƒ¨è‡ªé€‚åº”ï¼šç²¾å·¥ç»†ä½œçš„åŒ äººç²¾ç¥
            return self._local_adaptive_mapping(float_img, params)
        else:
            # ğŸŒ å…¨å±€è‡ªé€‚åº”ï¼šç»Ÿä¸€å’Œè°çš„ä¸–ç•Œè§‚
            return self._global_adaptive_mapping(float_img, params)

    def _global_adaptive_mapping(self, float_img: np.ndarray,
                               params: AdaptiveLogParams) -> np.ndarray:
        """
        ğŸŒ å…¨å±€è‡ªé€‚åº”æ˜ å°„ï¼šç»Ÿä¸€çš„è§†è§‰å¤„ç†å“²å­¦

        é‡‡ç”¨å…¨å›¾ç»Ÿä¸€çš„å‚æ•°ï¼Œä¿æŒæ•´ä½“çš„åè°ƒæ„Ÿ

        Args:
            float_img: æµ®ç‚¹å‹å›¾åƒ
            params: è‡ªé€‚åº”å‚æ•°

        Returns:
            å…¨å±€è‡ªé€‚åº”å¤„ç†åçš„å›¾åƒ
        """
        # ğŸ“Š è®¡ç®—å…¨å›¾æœ€å¤§å€¼ï¼šå®è§‚è§†è§’çš„ç»Ÿè®¡åˆ†æ
        max_val = np.max(float_img)
        mean_val = np.mean(float_img)

        if max_val <= 0:
            return np.zeros_like(float_img, dtype=np.uint8)

        # ğŸ§® è®¡ç®—è‡ªé€‚åº”ç¼©æ”¾å› å­
        # æ ¹æ®å›¾åƒçš„åŠ¨æ€èŒƒå›´è‡ªåŠ¨è°ƒæ•´æ˜ å°„å¼ºåº¦
        scale = params.max_scale / np.log10(max_val + 1.0)

        # ğŸ¨ æ™ºèƒ½åç½®è°ƒæ•´ï¼šæ ¹æ®æ•´ä½“äº®åº¦å¾®è°ƒ
        adaptive_bias = params.bias + 0.15 * (128 - mean_val) / 128

        # âœ¨ åº”ç”¨æ˜ å°„ï¼šæ•°å­¦ä¸è‰ºæœ¯çš„å®Œç¾èåˆ
        log_img = np.log(float_img + 1.0) * scale + adaptive_bias

        return np.clip(log_img, 0, 255).astype(np.uint8)

    def _local_adaptive_mapping(self, float_img: np.ndarray,
                              params: AdaptiveLogParams) -> np.ndarray:
        """
        ğŸ­ å±€éƒ¨è‡ªé€‚åº”æ˜ å°„ï¼šç²¾å·¥ç»†ä½œçš„è‰ºæœ¯

        ä¸ºæ¯ä¸ªåƒç´ æ ¹æ®å…¶é‚»åŸŸç‰¹å¾è¿›è¡Œä¸ªæ€§åŒ–å¤„ç†
        å¦‚åŒç²¾å¿ƒç…§æ–™æ¯æ ªæ¤ç‰©çš„å›­ä¸ï¼Œä½“ç°å› åœ°åˆ¶å®œçš„æ™ºæ…§

        Args:
            float_img: æµ®ç‚¹å‹å›¾åƒ
            params: è‡ªé€‚åº”å‚æ•°

        Returns:
            å±€éƒ¨è‡ªé€‚åº”å¤„ç†åçš„å›¾åƒ
        """
        h, w = float_img.shape[:2]
        result = np.zeros_like(float_img)

        # ğŸ“ è®¡ç®—çª—å£å¤§å°ï¼šè§‚å¯Ÿä¸–ç•Œçš„è§†é‡
        # çª—å£å¤§å°å†³å®šäº†"å±€éƒ¨"çš„å®šä¹‰èŒƒå›´
        window_size = int(min(h, w) * params.window_ratio)
        half_window = window_size // 2

        print(f"ğŸ” å¼€å§‹å±€éƒ¨è‡ªé€‚åº”å¤„ç†ï¼Œçª—å£å¤§å°: {window_size}x{window_size}")

        # ğŸ¨ ä¸ºæ¯ä¸ªåƒç´ è®¡ç®—å±€éƒ¨æ˜ å°„
        # è¿™æ˜¯ä¸€ä¸ªè®¡ç®—å¯†é›†çš„è¿‡ç¨‹ï¼Œä½“ç°ç²¾å·¥ç»†ä½œçš„ç²¾ç¥
        for y in range(h):
            if y % (h // 10) == 0:  # æ˜¾ç¤ºè¿›åº¦
                print(f"ğŸ“ å¤„ç†è¿›åº¦: {y/h*100:.1f}%")

            for x in range(w):
                # ğŸ” å®šä¹‰å±€éƒ¨åŒºåŸŸï¼šå½“å‰åƒç´ çš„"å½±å“åœˆ"
                y_min = max(0, y - half_window)
                y_max = min(h, y + half_window + 1)
                x_min = max(0, x - half_window)
                x_max = min(w, x + half_window + 1)

                # ğŸ“Š è®¡ç®—å±€éƒ¨ç»Ÿè®¡ç‰¹å¾
                local_region = float_img[y_min:y_max, x_min:x_max]
                local_max = np.max(local_region)
                local_mean = np.mean(local_region)

                if local_max <= 0:
                    result[y, x] = 0
                    continue

                # ğŸ§® è®¡ç®—å±€éƒ¨è‡ªé€‚åº”å‚æ•°
                # æ¯ä¸ªåƒç´ éƒ½æœ‰å…¶ç‹¬ç‰¹çš„å¤„ç†å‚æ•°
                local_scale = params.max_scale / np.log10(local_max + 1.0)
                local_bias = params.bias + 0.1 * (128 - local_mean) / 128

                # âœ¨ åº”ç”¨å±€éƒ¨æ˜ å°„
                current_pixel = float_img[y, x]
                mapped_pixel = np.log(current_pixel + 1.0) * local_scale + local_bias
                result[y, x] = np.clip(mapped_pixel, 0, 255)

        print("âœ… å±€éƒ¨è‡ªé€‚åº”å¤„ç†å®Œæˆ")
        return result.astype(np.uint8)

    def enhanced_adaptive_mapping(self, image: np.ndarray,
                                params: Optional[AdaptiveLogParams] = None,
                                tone_curve: bool = True) -> np.ndarray:
        """
        âœ¨ å¢å¼ºå‹è‡ªé€‚åº”æ˜ å°„ï¼šè‰ºæœ¯ä¸æŠ€æœ¯çš„å®Œç¾èåˆ

        åœ¨åŸºç¡€è‡ªé€‚åº”æ˜ å°„çš„åŸºç¡€ä¸Šï¼Œæ·»åŠ è‰²è°ƒæ›²çº¿ä¼˜åŒ–
        å¦‚åŒæ‘„å½±å¸ˆçš„åæœŸè°ƒè‰²ï¼Œè¿½æ±‚æ›´åŠ å®Œç¾çš„è§†è§‰æ•ˆæœ

        Args:
            image: è¾“å…¥å›¾åƒ
            params: æ˜ å°„å‚æ•°
            tone_curve: æ˜¯å¦åº”ç”¨Så‹è‰²è°ƒæ›²çº¿å¢å¼º

        Returns:
            å¢å¼ºå¤„ç†åçš„å›¾åƒï¼Œå±•ç°æŠ€æœ¯ä¸è‰ºæœ¯çš„åŒé‡ç¾æ„Ÿ
        """
        # ğŸŒŸ å…ˆåº”ç”¨åŸºç¡€è‡ªé€‚åº”æ˜ å°„
        basic_result = self.adaptive_log_mapping(image, params)

        if not tone_curve:
            return basic_result

        # ğŸ¨ åº”ç”¨Så‹è‰²è°ƒæ›²çº¿å¢å¼ºå¯¹æ¯”åº¦
        # Sæ›²çº¿èƒ½å¤Ÿåœ¨ä¿æŒä¸­é—´è°ƒçš„åŒæ—¶å¢å¼ºå¯¹æ¯”åº¦
        p = params or self.params
        enhanced = self._apply_s_curve(basic_result, p.tone_curve_strength)

        return enhanced

    def _apply_s_curve(self, image: np.ndarray, strength: float = 0.3) -> np.ndarray:
        """
        ğŸ¨ åº”ç”¨Så‹è‰²è°ƒæ›²çº¿ï¼šä¼˜é›…çš„å¯¹æ¯”åº¦å¢å¼º

        Så‹æ›²çº¿æ˜¯æ‘„å½±åæœŸä¸­çš„ç»å…¸æŠ€æ³•
        å®ƒèƒ½å¤Ÿåœ¨ä¿æŒè‡ªç„¶å¤–è§‚çš„åŒæ—¶å¢å¼ºå›¾åƒçš„å±‚æ¬¡æ„Ÿ

        Args:
            image: è¾“å…¥å›¾åƒ
            strength: æ›²çº¿å¼ºåº¦ï¼Œæ§åˆ¶Så‹æ›²çº¿çš„å¼¯æ›²ç¨‹åº¦

        Returns:
            åº”ç”¨Sæ›²çº¿åçš„å›¾åƒ
        """
        # åˆ›å»ºSå‹æŸ¥æ‰¾è¡¨
        lut = np.zeros(256, dtype=np.uint8)

        for i in range(256):
            # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
            x = i / 255.0

            # åº”ç”¨Så‹å‡½æ•°ï¼šä¿®æ”¹çš„sigmoidå‡½æ•°
            # è¿™ä¸ªå‡½æ•°åœ¨0.5å¤„æœ‰æ‹ç‚¹ï¼Œå½¢æˆç»å…¸çš„Så‹æ›²çº¿
            s_value = 1.0 / (1.0 + np.exp(-strength * 10 * (x - 0.5)))

            # é‡æ–°æ˜ å°„åˆ°[0,255]èŒƒå›´
            lut[i] = np.clip(s_value * 255, 0, 255).astype(np.uint8)

        # åº”ç”¨æŸ¥æ‰¾è¡¨è¿›è¡Œå¿«é€Ÿæ˜ å°„
        return cv2.LUT(image, lut)

    def analyze_image_statistics(self, image: np.ndarray) -> Dict[str, Any]:
        """
        ğŸ“Š åˆ†æå›¾åƒç»Ÿè®¡ç‰¹å¾ï¼šäº†è§£å›¾åƒçš„å†…åœ¨ç‰¹è´¨

        é€šè¿‡ç»Ÿè®¡åˆ†æäº†è§£å›¾åƒçš„ç‰¹å¾ï¼Œä¸ºè‡ªé€‚åº”å¤„ç†æä¾›ä¾æ®

        Args:
            image: è¾“å…¥å›¾åƒ

        Returns:
            åŒ…å«å„ç§ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        stats = {}

        # åŸºç¡€ç»Ÿè®¡
        stats['shape'] = image.shape
        stats['dtype'] = image.dtype
        stats['min'] = np.min(image)
        stats['max'] = np.max(image)
        stats['mean'] = np.mean(image)
        stats['std'] = np.std(image)
        stats['median'] = np.median(image)

        # åŠ¨æ€èŒƒå›´åˆ†æ
        stats['dynamic_range'] = stats['max'] - stats['min']
        stats['contrast_ratio'] = stats['max'] / max(stats['min'], 1)

        # äº®åº¦åˆ†å¸ƒåˆ†æ
        if len(image.shape) == 3:
            # å½©è‰²å›¾åƒï¼šè½¬æ¢ä¸ºç°åº¦è¿›è¡Œåˆ†æ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        else:
            # ç°åº¦å›¾åƒï¼šç›´æ¥è®¡ç®—ç›´æ–¹å›¾
            hist = cv2.calcHist([image], [0], None, [256], [0, 256])

        stats['histogram'] = hist.flatten()

        # äº®åº¦åˆ†å¸ƒç‰¹å¾
        total_pixels = image.shape[0] * image.shape[1]
        dark_pixels = np.sum(hist[:85]) / total_pixels     # æš—éƒ¨åƒç´ æ¯”ä¾‹
        mid_pixels = np.sum(hist[85:170]) / total_pixels   # ä¸­é—´è°ƒåƒç´ æ¯”ä¾‹
        bright_pixels = np.sum(hist[170:]) / total_pixels  # äº®éƒ¨åƒç´ æ¯”ä¾‹

        stats['brightness_distribution'] = {
            'dark_ratio': dark_pixels,
            'mid_ratio': mid_pixels,
            'bright_ratio': bright_pixels
        }

        # æ¨èå‚æ•°
        stats['recommended_params'] = self._recommend_parameters(stats)

        return stats

    def _recommend_parameters(self, stats: Dict[str, Any]) -> AdaptiveLogParams:
        """
        ğŸ¯ æ ¹æ®å›¾åƒç»Ÿè®¡ç‰¹å¾æ¨èå‚æ•°

        åŸºäºå›¾åƒç‰¹å¾è‡ªåŠ¨æ¨èæœ€ä½³çš„å¤„ç†å‚æ•°
        ä½“ç°ç®—æ³•çš„æ™ºèƒ½åŒ–å’Œäººæ€§åŒ–ç‰¹ç‚¹

        Args:
            stats: å›¾åƒç»Ÿè®¡ä¿¡æ¯

        Returns:
            æ¨èçš„è‡ªé€‚åº”å¯¹æ•°æ˜ å°„å‚æ•°
        """
        # åŸºç¡€å‚æ•°
        bias = 0.85
        max_scale = 100.0
        local_adaptation = False
        window_ratio = 0.125

        # æ ¹æ®åŠ¨æ€èŒƒå›´è°ƒæ•´
        if stats['dynamic_range'] > 200:
            # é«˜åŠ¨æ€èŒƒå›´å›¾åƒï¼šå¢å¼ºæ˜ å°„å¼ºåº¦
            max_scale = 150.0
            bias = 0.9
        elif stats['dynamic_range'] < 100:
            # ä½åŠ¨æ€èŒƒå›´å›¾åƒï¼šæ¸©å’Œå¤„ç†
            max_scale = 80.0
            bias = 0.8

        # æ ¹æ®äº®åº¦åˆ†å¸ƒè°ƒæ•´
        brightness_dist = stats['brightness_distribution']
        if brightness_dist['dark_ratio'] > 0.6:
            # å›¾åƒåæš—ï¼šå¢åŠ åç½®
            bias += 0.2
        elif brightness_dist['bright_ratio'] > 0.6:
            # å›¾åƒåäº®ï¼šå‡å°‘åç½®
            bias -= 0.2

        # æ ¹æ®å›¾åƒå¤§å°å†³å®šæ˜¯å¦ä½¿ç”¨å±€éƒ¨è‡ªé€‚åº”
        total_pixels = stats['shape'][0] * stats['shape'][1]
        if total_pixels > 1000000:  # å¤§äº100ä¸‡åƒç´ 
            # å¤§å›¾åƒå¯èƒ½éœ€è¦å±€éƒ¨è‡ªé€‚åº”
            local_adaptation = True
            window_ratio = 0.1

        return AdaptiveLogParams(
            bias=np.clip(bias, 0.0, 2.0),
            max_scale=max_scale,
            local_adaptation=local_adaptation,
            window_ratio=window_ratio
        )

    def performance_test(self, image: np.ndarray, iterations: int = 5) -> Dict[str, float]:
        """
        âš¡ æ€§èƒ½æµ‹è¯•ï¼šè¯„ä¼°ç®—æ³•çš„è¿è¡Œæ•ˆç‡

        å¯¹ä¸åŒå¤„ç†æ–¹æ³•è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•

        Args:
            image: æµ‹è¯•å›¾åƒ
            iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°

        Returns:
            å„ç§æ–¹æ³•çš„å¹³å‡æ‰§è¡Œæ—¶é—´
        """
        print(f"âš¡ å¼€å§‹æ€§èƒ½æµ‹è¯•ï¼Œå›¾åƒå°ºå¯¸: {image.shape}, è¿­ä»£æ¬¡æ•°: {iterations}")

        results = {}

        # æµ‹è¯•åŸºç¡€å¯¹æ•°æ˜ å°„
        start_time = time.time()
        for _ in range(iterations):
            self.basic_log_mapping(image)
        results['basic_log_mapping'] = (time.time() - start_time) / iterations

        # æµ‹è¯•å…¨å±€è‡ªé€‚åº”æ˜ å°„
        params = AdaptiveLogParams(local_adaptation=False)
        start_time = time.time()
        for _ in range(iterations):
            self.adaptive_log_mapping(image, params)
        results['global_adaptive'] = (time.time() - start_time) / iterations

        # æµ‹è¯•å¢å¼ºå‹æ˜ å°„
        start_time = time.time()
        for _ in range(iterations):
            self.enhanced_adaptive_mapping(image, params)
        results['enhanced_adaptive'] = (time.time() - start_time) / iterations

        # å¦‚æœå›¾åƒä¸å¤ªå¤§ï¼Œæµ‹è¯•å±€éƒ¨è‡ªé€‚åº”
        if image.shape[0] * image.shape[1] < 200000:
            params_local = AdaptiveLogParams(local_adaptation=True, window_ratio=0.1)
            start_time = time.time()
            for _ in range(max(1, iterations // 3)):  # å±€éƒ¨è‡ªé€‚åº”è¾ƒæ…¢ï¼Œå‡å°‘è¿­ä»£æ¬¡æ•°
                self.adaptive_log_mapping(image, params_local)
            results['local_adaptive'] = (time.time() - start_time) / max(1, iterations // 3)

        # æ‰“å°ç»“æœ
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
        for method, time_cost in results.items():
            print(f"   {method}: {time_cost:.4f}s")

        return results

    def artistic_showcase(self, image: np.ndarray, save_path: Optional[str] = None) -> None:
        """
        ğŸ­ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„è‰ºæœ¯å±•ç¤ºï¼šå±•ç°ç®—æ³•çš„æ— é™å¯èƒ½

        åˆ›å»ºä¸€ä¸ªè§†è§‰è‰ºæœ¯é¦†ï¼Œå±•ç¤ºå„ç§å‚æ•°ç»„åˆçš„è‰ºæœ¯æ•ˆæœ
        è®©è§‚è€…ç›´è§‚åœ°æ„Ÿå—æ•°å­¦ä¸ç¾å­¦çš„å¯¹è¯

        Args:
            image: è¾“å…¥å›¾åƒ
            save_path: ä¿å­˜è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜å±•ç¤ºå›¾
        """
        print("ğŸ¨ å¼€å§‹åˆ›ä½œè‡ªé€‚åº”å¯¹æ•°æ˜ å°„è‰ºæœ¯ä½œå“...")

        # ğŸ¨ åˆ›å»ºä¸åŒé£æ ¼çš„è‰ºæœ¯ä½œå“
        effects = {
            "ğŸ“· åŸå§‹å›¾åƒ": image,
            "ğŸŒ… åŸºç¡€å¯¹æ•°æ˜ å°„": self.basic_log_mapping(image),
            "ğŸŒˆ å…¨å±€è‡ªé€‚åº”": self.adaptive_log_mapping(
                image, AdaptiveLogParams(bias=0.85, max_scale=100.0, local_adaptation=False)
            ),
            "ğŸ­ æ¨èå‚æ•°": self.adaptive_log_mapping(
                image, self.analyze_image_statistics(image)['recommended_params']
            ),
            "âœ¨ å¢å¼ºå‹æ˜ å°„": self.enhanced_adaptive_mapping(image),
            "ğŸŒŸ é«˜å¯¹æ¯”åº¦": self.adaptive_log_mapping(
                image, AdaptiveLogParams(bias=1.0, max_scale=150.0)
            ),
            "ğŸŒ™ æŸ”å’Œæ˜ å°„": self.adaptive_log_mapping(
                image, AdaptiveLogParams(bias=0.7, max_scale=80.0)
            ),
            "ğŸ”¥ å¼ºåŒ–ç»†èŠ‚": self.enhanced_adaptive_mapping(
                image, AdaptiveLogParams(bias=0.9, max_scale=200.0), tone_curve=True
            )
        }

        # ğŸ–¼ï¸ åˆ›é€ è§†è§‰è‰ºæœ¯é¦†
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('ğŸŒŸ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„è‰ºæœ¯é¦†ï¼šæ•°å­¦ä¸ç¾å­¦çš„å¯¹è¯',
                    fontsize=16, fontweight='bold', y=0.98)

        for i, (title, effect_image) in enumerate(effects.items()):
            row, col = i // 4, i % 4

            # æ˜¾ç¤ºå›¾åƒ
            if len(effect_image.shape) == 3:
                # å½©è‰²å›¾åƒï¼šBGRè½¬RGBæ˜¾ç¤º
                display_image = cv2.cvtColor(effect_image, cv2.COLOR_BGR2RGB)
                axes[row, col].imshow(display_image)
            else:
                # ç°åº¦å›¾åƒ
                axes[row, col].imshow(effect_image, cmap='gray')

            axes[row, col].set_title(title, fontsize=11, pad=10)
            axes[row, col].axis('off')

            # æ·»åŠ ç¾åŒ–è¾¹æ¡†
            for spine in axes[row, col].spines.values():
                spine.set_linewidth(2)
                spine.set_color('lightgray')

        plt.tight_layout()
        plt.subplots_adjust(top=0.93, hspace=0.15, wspace=0.1)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            print(f"ğŸ’¾ è‰ºæœ¯å±•ç¤ºå·²ä¿å­˜è‡³: {save_path}")

        plt.show()
        print("ğŸ¨ è‰ºæœ¯å±•ç¤ºå®Œæˆï¼Œæ„Ÿè°¢æ¬£èµæ•°å­¦ä¸ç¾å­¦çš„å¯¹è¯ï¼")

    def interactive_demo(self, image: np.ndarray) -> None:
        """
        ğŸ® äº¤äº’å¼æ¼”ç¤ºï¼šå®æ—¶è°ƒæ•´å‚æ•°ä½“éªŒç®—æ³•æ•ˆæœ

        æä¾›ä¸€ä¸ªç®€åŒ–çš„äº¤äº’ç•Œé¢ï¼Œè®©ç”¨æˆ·ä½“éªŒå‚æ•°è°ƒæ•´çš„å³æ—¶æ•ˆæœ

        Args:
            image: æ¼”ç¤ºå›¾åƒ
        """
        print("ğŸ® å¯åŠ¨äº¤äº’å¼æ¼”ç¤ºæ¨¡å¼")
        print("ğŸ’¡ æç¤ºï¼šä¿®æ”¹ä¸‹é¢çš„å‚æ•°å€¼ï¼Œè§‚å¯Ÿç®—æ³•æ•ˆæœçš„å˜åŒ–")

        # åˆ›å»ºå‚æ•°é€‰é¡¹
        bias_options = [0.5, 0.7, 0.85, 1.0, 1.2]
        scale_options = [50.0, 80.0, 100.0, 120.0, 150.0]

        print("\nğŸ¯ å¯é€‰å‚æ•°ç»„åˆ:")
        combinations = []
        for i, bias in enumerate(bias_options):
            for j, scale in enumerate(scale_options):
                combinations.append((bias, scale))
                if len(combinations) <= 6:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    print(f"   {len(combinations)}: bias={bias}, max_scale={scale}")

        # æ˜¾ç¤ºå‡ ä¸ªä»£è¡¨æ€§ç»„åˆçš„æ•ˆæœ
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('ğŸ® äº¤äº’å¼å‚æ•°æ¼”ç¤ºï¼šæ¢ç´¢å‚æ•°ç©ºé—´çš„è‰ºæœ¯',
                    fontsize=14, fontweight='bold')

        selected_combinations = combinations[:6]
        for i, (bias, scale) in enumerate(selected_combinations):
            row, col = i // 3, i % 3

            params = AdaptiveLogParams(bias=bias, max_scale=scale)
            result = self.adaptive_log_mapping(image, params)

            if len(result.shape) == 3:
                display_image = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
                axes[row, col].imshow(display_image)
            else:
                axes[row, col].imshow(result, cmap='gray')

            axes[row, col].set_title(f'bias={bias}, scale={scale}', fontsize=10)
            axes[row, col].axis('off')

        plt.tight_layout()
        plt.show()

        print("ğŸ® äº¤äº’å¼æ¼”ç¤ºå®Œæˆï¼ä½ å¯ä»¥åœ¨ä»£ç ä¸­ä¿®æ”¹å‚æ•°æ¥æ¢ç´¢æ›´å¤šæ•ˆæœ")

def create_demo_interface():
    """
    ğŸš€ åˆ›å»ºæ¼”ç¤ºç•Œé¢ï¼šå±•ç¤ºè‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„å®Œæ•´åŠŸèƒ½

    è¿™ä¸ªå‡½æ•°æä¾›äº†ç®—æ³•çš„å®Œæ•´æ¼”ç¤ºï¼ŒåŒ…æ‹¬ï¼š
    - åŸºç¡€åŠŸèƒ½å±•ç¤º
    - æ€§èƒ½æµ‹è¯•
    - è‰ºæœ¯æ•ˆæœå±•ç¤º
    - å‚æ•°æ¨è
    """
    print("ğŸŒŸ" + "="*60)
    print("ğŸ¨      è‡ªé€‚åº”å¯¹æ•°æ˜ å°„ç®—æ³•æ¼”ç¤ºç³»ç»Ÿ")
    print("ğŸŒŸ" + "="*60)
    print("ğŸ“ åŠŸèƒ½è¯´æ˜ï¼š")
    print("   1. åŸºç¡€å¯¹æ•°æ˜ å°„ - å‘ç°å¯¹æ•°ç¾å­¦çš„ç¬¬ä¸€æ­¥")
    print("   2. è‡ªé€‚åº”æ˜ å°„ - æ™ºæ…§é€‰æ‹©çš„æ•°å­¦è¯—ç¯‡")
    print("   3. å¢å¼ºå‹æ˜ å°„ - è‰ºæœ¯ä¸æŠ€æœ¯çš„å®Œç¾èåˆ")
    print("   4. æ€§èƒ½æµ‹è¯• - ç®—æ³•æ•ˆç‡çš„é‡åŒ–è¯„ä¼°")
    print("   5. è‰ºæœ¯å±•ç¤º - æ•°å­¦ä¸ç¾å­¦çš„è§†è§‰å¯¹è¯")
    print("ğŸŒŸ" + "="*60)

def main():
    """
    ğŸ¯ ä¸»å‡½æ•°ï¼šè‡ªé€‚åº”å¯¹æ•°æ˜ å°„ç®—æ³•çš„å®Œæ•´æ¼”ç¤º

    æä¾›å‘½ä»¤è¡Œæ¥å£ï¼Œæ”¯æŒï¼š
    - å›¾åƒæ–‡ä»¶å¤„ç†
    - å‚æ•°è‡ªå®šä¹‰
    - ç»“æœä¿å­˜
    - æ€§èƒ½æµ‹è¯•
    """
    parser = argparse.ArgumentParser(
        description="ğŸŒŸ è‡ªé€‚åº”å¯¹æ•°æ˜ å°„ç®—æ³• - æ•°å­—ä¸–ç•Œçš„æ™ºæ…§çœ¼é•œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ¨ ä½¿ç”¨ç¤ºä¾‹:
  python adaptive_logarithmic_mapping.py --input image.jpg --output result.jpg
  python adaptive_logarithmic_mapping.py --input image.jpg --bias 0.9 --scale 120
  python adaptive_logarithmic_mapping.py --input image.jpg --local --showcase
  python adaptive_logarithmic_mapping.py --demo
        """
    )

    parser.add_argument('--input', '-i', type=str,
                       help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--output', '-o', type=str,
                       help='è¾“å‡ºå›¾åƒè·¯å¾„')
    parser.add_argument('--bias', type=float, default=0.85,
                       help='åç½®å‚æ•° (default: 0.85)')
    parser.add_argument('--scale', type=float, default=100.0,
                       help='æœ€å¤§ç¼©æ”¾å› å­ (default: 100.0)')
    parser.add_argument('--local', action='store_true',
                       help='å¯ç”¨å±€éƒ¨è‡ªé€‚åº”')
    parser.add_argument('--enhanced', action='store_true',
                       help='ä½¿ç”¨å¢å¼ºå‹æ˜ å°„')
    parser.add_argument('--showcase', action='store_true',
                       help='æ˜¾ç¤ºè‰ºæœ¯æ•ˆæœå±•ç¤º')
    parser.add_argument('--performance', action='store_true',
                       help='è¿è¡Œæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--interactive', action='store_true',
                       help='å¯åŠ¨äº¤äº’å¼æ¼”ç¤º')
    parser.add_argument('--demo', action='store_true',
                       help='è¿è¡Œå®Œæ•´æ¼”ç¤ºï¼ˆä½¿ç”¨å†…ç½®æµ‹è¯•å›¾åƒï¼‰')

    args = parser.parse_args()

    # åˆ›å»ºæ¼”ç¤ºç•Œé¢
    create_demo_interface()

    # åˆå§‹åŒ–ç®—æ³•è‰ºæœ¯å®¶
    params = AdaptiveLogParams(
        bias=args.bias,
        max_scale=args.scale,
        local_adaptation=args.local
    )
    artist = AdaptiveLogArtist(params)

    # å¤„ç†ä¸åŒçš„è¿è¡Œæ¨¡å¼
    if args.demo:
        # æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨å†…ç½®æµ‹è¯•å›¾åƒ
        print("ğŸ­ å¯åŠ¨æ¼”ç¤ºæ¨¡å¼ï¼Œä½¿ç”¨å†…ç½®æµ‹è¯•å›¾åƒ...")

        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = create_test_image()

        # åˆ†æå›¾åƒ
        stats = artist.analyze_image_statistics(test_image)
        print(f"\nğŸ“Š å›¾åƒç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å°ºå¯¸: {stats['shape']}")
        print(f"   åŠ¨æ€èŒƒå›´: {stats['dynamic_range']}")
        print(f"   å¹³å‡äº®åº¦: {stats['mean']:.2f}")

        # è‰ºæœ¯å±•ç¤º
        if args.showcase or True:  # æ¼”ç¤ºæ¨¡å¼é»˜è®¤æ˜¾ç¤º
            artist.artistic_showcase(test_image)

        # æ€§èƒ½æµ‹è¯•
        if args.performance or True:  # æ¼”ç¤ºæ¨¡å¼é»˜è®¤æµ‹è¯•
            artist.performance_test(test_image)

        # äº¤äº’å¼æ¼”ç¤º
        if args.interactive:
            artist.interactive_demo(test_image)

    elif args.input:
        # æ–‡ä»¶å¤„ç†æ¨¡å¼
        if not os.path.exists(args.input):
            print(f"ğŸš« é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ {args.input} ä¸å­˜åœ¨")
            return

        # è¯»å–å›¾åƒ
        image = cv2.imread(args.input)
        if image is None:
            print(f"ğŸš« é”™è¯¯ï¼šæ— æ³•è¯»å–å›¾åƒæ–‡ä»¶ {args.input}")
            return

        print(f"ğŸ“– æˆåŠŸè¯»å–å›¾åƒ: {args.input}, å°ºå¯¸: {image.shape}")

        # åˆ†æå›¾åƒå¹¶æ¨èå‚æ•°
        stats = artist.analyze_image_statistics(image)
        recommended = stats['recommended_params']
        print(f"\nğŸ¯ æ¨èå‚æ•°: bias={recommended.bias:.2f}, scale={recommended.max_scale:.1f}")

        # é€‰æ‹©å¤„ç†æ–¹æ³•
        if args.enhanced:
            result = artist.enhanced_adaptive_mapping(image, params)
            print("âœ¨ ä½¿ç”¨å¢å¼ºå‹è‡ªé€‚åº”æ˜ å°„")
        else:
            result = artist.adaptive_log_mapping(image, params)
            print("ğŸŒˆ ä½¿ç”¨æ ‡å‡†è‡ªé€‚åº”æ˜ å°„")

        # ä¿å­˜ç»“æœ
        if args.output:
            cv2.imwrite(args.output, result)
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {args.output}")

        # å…¶ä»–åŠŸèƒ½
        if args.showcase:
            artist.artistic_showcase(image)

        if args.performance:
            artist.performance_test(image)

        if args.interactive:
            artist.interactive_demo(image)

    else:
        print("ğŸ¤” è¯·æä¾›è¾“å…¥å›¾åƒè·¯å¾„æˆ–ä½¿ç”¨ --demo è¿è¡Œæ¼”ç¤º")
        print("ğŸ’¡ ä½¿ç”¨ --help æŸ¥çœ‹è¯¦ç»†å¸®åŠ©ä¿¡æ¯")

def create_test_image(size: Tuple[int, int] = (512, 512)) -> np.ndarray:
    """
    ğŸ¨ åˆ›å»ºæµ‹è¯•å›¾åƒï¼šç”¨äºæ¼”ç¤ºçš„è‰ºæœ¯ç”»å¸ƒ

    ç”Ÿæˆä¸€ä¸ªåŒ…å«ä¸åŒäº®åº¦åŒºåŸŸçš„æµ‹è¯•å›¾åƒ
    ç”¨äºå±•ç¤ºè‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„æ•ˆæœ

    Args:
        size: å›¾åƒå°ºå¯¸

    Returns:
        æµ‹è¯•å›¾åƒ
    """
    h, w = size
    image = np.zeros((h, w, 3), dtype=np.uint8)

    # åˆ›å»ºå¾„å‘æ¸å˜
    center_x, center_y = w // 2, h // 2
    max_radius = min(center_x, center_y)

    for y in range(h):
        for x in range(w):
            # è®¡ç®—åˆ°ä¸­å¿ƒçš„è·ç¦»
            distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)

            # åˆ›å»ºå¤æ‚çš„äº®åº¦åˆ†å¸ƒ
            if distance < max_radius * 0.3:
                # ä¸­å¿ƒï¼šé«˜äº®åŒºåŸŸ
                intensity = 200 + 55 * np.sin(distance * 0.1)
            elif distance < max_radius * 0.6:
                # ä¸­é—´ï¼šä¸­ç­‰äº®åº¦
                intensity = 100 + 50 * np.cos(distance * 0.05)
            elif distance < max_radius * 0.9:
                # å¤–ç¯ï¼šè¾ƒæš—åŒºåŸŸ
                intensity = 50 + 30 * np.sin(distance * 0.02)
            else:
                # è¾¹ç¼˜ï¼šå¾ˆæš—
                intensity = 20 + 10 * np.random.random()

            # æ·»åŠ ä¸€äº›é¢œè‰²å˜åŒ–
            image[y, x] = [
                np.clip(intensity + 20 * np.sin(x * 0.01), 0, 255),
                np.clip(intensity, 0, 255),
                np.clip(intensity + 20 * np.cos(y * 0.01), 0, 255)
            ]

    return image

if __name__ == "__main__":
    # ğŸŒŸ æ¬¢è¿æ¥åˆ°è‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„æ•°å­¦è‰ºæœ¯ä¸–ç•Œ
    print("ğŸ¨ æ¬¢è¿ä½¿ç”¨è‡ªé€‚åº”å¯¹æ•°æ˜ å°„ç®—æ³• - æ•°å­—ä¸–ç•Œçš„æ™ºæ…§çœ¼é•œ")
    print("âœ¨ è®©æ•°å­¦ä¹‹ç¾ä¸è§†è§‰è‰ºæœ¯åœ¨åƒç´ ä¸­ç›¸é‡...")

    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ­ ç”¨æˆ·ä¸­æ–­ï¼Œæ„Ÿè°¢ä½“éªŒè‡ªé€‚åº”å¯¹æ•°æ˜ å°„çš„è‰ºæœ¯ä¹‹æ—…ï¼")
    except Exception as e:
        print(f"\nğŸš« ç¨‹åºå¼‚å¸¸: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥å‚æ•°å’Œå›¾åƒæ–‡ä»¶")

    print("ï¿½ï¿½ æ¢ç´¢æ°¸æ— æ­¢å¢ƒï¼Œåˆ›é€ æ— é™å¯èƒ½ï¼")